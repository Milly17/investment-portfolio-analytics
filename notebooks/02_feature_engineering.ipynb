{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380c4ee8-f998-4979-b6f8-a7f2eae25b36",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db5d92-a605-4ee0-9070-6bc511223bc1",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a4ba3d-8a8e-49c0-9012-613d926624f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "Economic Indicators: (4005, 5)\n",
      "Fama-French Factors: (180, 4)\n",
      "Stock Prices: (3812, 48)\n",
      "World Bank Data: (70, 6)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = Path(\"../data\")\n",
    "RAW_DATA_PATH = DATA_PATH / \"raw\"\n",
    "PROCESSED_DATA_PATH = DATA_PATH / \"processed\"\n",
    "\n",
    "# Create processed data directory if it doesn't exist\n",
    "if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "    os.makedirs(PROCESSED_DATA_PATH)\n",
    "\n",
    "# Load the raw data\n",
    "def load_data():\n",
    "    \"\"\"Load all raw data sources\"\"\"\n",
    "    print(\"Loading data files...\")\n",
    "    \n",
    "    economic_indicators = pd.read_parquet(RAW_DATA_PATH / \"economic_indicators.parquet\")\n",
    "    fama_french_factors = pd.read_parquet(RAW_DATA_PATH / \"fama_french_factors.parquet\")\n",
    "    stock_prices = pd.read_parquet(RAW_DATA_PATH / \"stock_prices.parquet\")\n",
    "    world_bank_data = pd.read_parquet(RAW_DATA_PATH / \"world_bank_data.parquet\")\n",
    "    \n",
    "    print(f\"Economic Indicators: {economic_indicators.shape}\")\n",
    "    print(f\"Fama-French Factors: {fama_french_factors.shape}\")\n",
    "    print(f\"Stock Prices: {stock_prices.shape}\")\n",
    "    print(f\"World Bank Data: {world_bank_data.shape}\")\n",
    "    \n",
    "    return economic_indicators, fama_french_factors, stock_prices, world_bank_data\n",
    "\n",
    "economic_indicators, fama_french_factors, stock_prices, world_bank_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e834a3-5099-4388-b41d-9114525a078b",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c70f9-c254-46ca-ad05-80c902005ed6",
   "metadata": {},
   "source": [
    "### 2.1 Economic Indicators Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4951fbb7-af53-435b-9e3d-c80c50a67e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Indicators - First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>T10Y2Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>14764.61</td>\n",
       "      <td>9.8</td>\n",
       "      <td>217.488</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GDP  UNRATE  CPIAUCSL  FEDFUNDS  T10Y2Y\n",
       "2010-01-01  14764.61     9.8   217.488      0.11     NaN\n",
       "2010-01-04       NaN     NaN       NaN       NaN    2.76\n",
       "2010-01-05       NaN     NaN       NaN       NaN    2.76\n",
       "2010-01-06       NaN     NaN       NaN       NaN    2.84\n",
       "2010-01-07       NaN     NaN       NaN       NaN    2.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Economic Indicators - Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4005 entries, 2010-01-01 to 2025-02-27\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   GDP       60 non-null     float64\n",
      " 1   UNRATE    181 non-null    float64\n",
      " 2   CPIAUCSL  181 non-null    float64\n",
      " 3   FEDFUNDS  181 non-null    float64\n",
      " 4   T10Y2Y    3791 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 187.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values by column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GDP         3945\n",
       "UNRATE      3824\n",
       "CPIAUCSL    3824\n",
       "FEDFUNDS    3824\n",
       "T10Y2Y       214\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>T10Y2Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>3791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20549.782617</td>\n",
       "      <td>5.788398</td>\n",
       "      <td>254.491083</td>\n",
       "      <td>1.246409</td>\n",
       "      <td>1.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4310.087947</td>\n",
       "      <td>2.234609</td>\n",
       "      <td>28.788096</td>\n",
       "      <td>1.728006</td>\n",
       "      <td>0.970092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14764.610000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>217.199000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-1.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17132.473750</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>233.669000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19565.619000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>244.243000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22834.810000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>266.625000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29719.647000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>319.086000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP      UNRATE    CPIAUCSL    FEDFUNDS       T10Y2Y\n",
       "count     60.000000  181.000000  181.000000  181.000000  3791.000000\n",
       "mean   20549.782617    5.788398  254.491083    1.246409     1.012933\n",
       "std     4310.087947    2.234609   28.788096    1.728006     0.970092\n",
       "min    14764.610000    3.400000  217.199000    0.050000    -1.080000\n",
       "25%    17132.473750    3.900000  233.669000    0.090000     0.240000\n",
       "50%    19565.619000    5.000000  244.243000    0.190000     1.010000\n",
       "75%    22834.810000    7.500000  266.625000    1.830000     1.710000\n",
       "max    29719.647000   14.800000  319.086000    5.330000     2.910000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date differences (frequency):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1 days    3213\n",
       "2 days      50\n",
       "3 days     741\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1 days    3213\n",
       "2 days      50\n",
       "3 days     741\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Economic Indicators - First 5 rows:\")\n",
    "display(economic_indicators.head())\n",
    "print(\"\\nEconomic Indicators - Information:\")\n",
    "display(economic_indicators.info())\n",
    "print(\"\\nMissing values by column:\")\n",
    "display(economic_indicators.isna().sum())\n",
    "\n",
    "# Brief statistical summary\n",
    "display(economic_indicators.describe())\n",
    "\n",
    "# Check frequency of data\n",
    "def check_data_frequency(df, date_column='date'):\n",
    "    \"\"\"Analyze the frequency of time series data\"\"\"\n",
    "    if date_column in df.columns:\n",
    "        df = df.set_index(date_column) if df.index.name != date_column else df\n",
    "    \n",
    "    # Calculate differences between consecutive dates\n",
    "    date_diffs = df.index.to_series().diff().value_counts().sort_index()\n",
    "    print(\"Date differences (frequency):\")\n",
    "    display(date_diffs)\n",
    "    \n",
    "    return date_diffs\n",
    "\n",
    "check_data_frequency(economic_indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f17cc-c67d-4b18-a05d-980bd1c8752b",
   "metadata": {},
   "source": [
    "### 2.2 Fama-French Factors Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61e6f80-1db1-426e-b38b-8e1c4ff1c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fama-French Factors - First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01</th>\n",
       "      <td>-0.0336</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03</th>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05</th>\n",
       "      <td>-0.0789</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mkt-RF     SMB     HML      RF\n",
       "Date                                   \n",
       "2010-01 -0.0336  0.0040  0.0043  0.0000\n",
       "2010-02  0.0340  0.0119  0.0322  0.0000\n",
       "2010-03  0.0631  0.0148  0.0221  0.0001\n",
       "2010-04  0.0200  0.0487  0.0289  0.0001\n",
       "2010-05 -0.0789  0.0009 -0.0244  0.0001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fama-French Factors - Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "PeriodIndex: 180 entries, 2010-01 to 2024-12\n",
      "Freq: M\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Mkt-RF  180 non-null    float64\n",
      " 1   SMB     180 non-null    float64\n",
      " 2   HML     180 non-null    float64\n",
      " 3   RF      180 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 7.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date differences (frequency):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "<MonthEnd>    179\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "<MonthEnd>    179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fama-French Factors - First 5 rows:\")\n",
    "display(fama_french_factors.head())\n",
    "print(\"\\nFama-French Factors - Information:\")\n",
    "display(fama_french_factors.info())\n",
    "check_data_frequency(fama_french_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534b82f-1ed5-4d3f-ade8-85ec445be372",
   "metadata": {},
   "source": [
    "### 2.3 Stock Prices Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b927e38-fcc3-48f9-a4e6-cef827d7f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Prices - First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"8\" halign=\"left\">GLD</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AGG</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">VEA</th>\n",
       "      <th colspan=\"8\" halign=\"left\">SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Capital Gains</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>...</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Capital Gains</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Capital Gains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>109.820000</td>\n",
       "      <td>110.139999</td>\n",
       "      <td>109.309998</td>\n",
       "      <td>109.800003</td>\n",
       "      <td>16224100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.665953</td>\n",
       "      <td>68.759046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.297736</td>\n",
       "      <td>86.071994</td>\n",
       "      <td>84.644927</td>\n",
       "      <td>86.026451</td>\n",
       "      <td>118944600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>109.879997</td>\n",
       "      <td>110.389999</td>\n",
       "      <td>109.260002</td>\n",
       "      <td>109.699997</td>\n",
       "      <td>14213100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.898712</td>\n",
       "      <td>69.031694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.973302</td>\n",
       "      <td>86.292114</td>\n",
       "      <td>85.662077</td>\n",
       "      <td>86.254158</td>\n",
       "      <td>111579900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>110.709999</td>\n",
       "      <td>111.769997</td>\n",
       "      <td>110.410004</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>24981900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.031678</td>\n",
       "      <td>69.031678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.170669</td>\n",
       "      <td>86.527437</td>\n",
       "      <td>86.102354</td>\n",
       "      <td>86.314896</td>\n",
       "      <td>116074400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>111.070000</td>\n",
       "      <td>111.290001</td>\n",
       "      <td>110.620003</td>\n",
       "      <td>110.820000</td>\n",
       "      <td>13609800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.925351</td>\n",
       "      <td>68.958594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.155501</td>\n",
       "      <td>86.785539</td>\n",
       "      <td>85.912596</td>\n",
       "      <td>86.679268</td>\n",
       "      <td>131091100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>111.519997</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>110.260002</td>\n",
       "      <td>111.370003</td>\n",
       "      <td>15894600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.065001</td>\n",
       "      <td>69.065001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.451523</td>\n",
       "      <td>87.005653</td>\n",
       "      <td>86.276938</td>\n",
       "      <td>86.967697</td>\n",
       "      <td>126402800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             GLD                                                \\\n",
       "Price             Open        High         Low       Close    Volume   \n",
       "Date                                                                   \n",
       "2010-01-04  109.820000  110.139999  109.309998  109.800003  16224100   \n",
       "2010-01-05  109.879997  110.389999  109.260002  109.699997  14213100   \n",
       "2010-01-06  110.709999  111.769997  110.410004  111.510002  24981900   \n",
       "2010-01-07  111.070000  111.290001  110.620003  110.820000  13609800   \n",
       "2010-01-08  111.519997  111.580002  110.260002  111.370003  15894600   \n",
       "\n",
       "Ticker                                                 AGG             ...  \\\n",
       "Price      Dividends Stock Splits Capital Gains       Open       High  ...   \n",
       "Date                                                                   ...   \n",
       "2010-01-04       0.0          0.0           0.0  68.665953  68.759046  ...   \n",
       "2010-01-05       0.0          0.0           0.0  68.898712  69.031694  ...   \n",
       "2010-01-06       0.0          0.0           0.0  69.031678  69.031678  ...   \n",
       "2010-01-07       0.0          0.0           0.0  68.925351  68.958594  ...   \n",
       "2010-01-08       0.0          0.0           0.0  69.065001  69.065001  ...   \n",
       "\n",
       "Ticker              VEA                      SPY                        \\\n",
       "Price      Stock Splits Capital Gains       Open       High        Low   \n",
       "Date                                                                     \n",
       "2010-01-04          0.0           0.0  85.297736  86.071994  84.644927   \n",
       "2010-01-05          0.0           0.0  85.973302  86.292114  85.662077   \n",
       "2010-01-06          0.0           0.0  86.170669  86.527437  86.102354   \n",
       "2010-01-07          0.0           0.0  86.155501  86.785539  85.912596   \n",
       "2010-01-08          0.0           0.0  86.451523  87.005653  86.276938   \n",
       "\n",
       "Ticker                                                                 \n",
       "Price           Close     Volume Dividends Stock Splits Capital Gains  \n",
       "Date                                                                   \n",
       "2010-01-04  86.026451  118944600       0.0          0.0           0.0  \n",
       "2010-01-05  86.254158  111579900       0.0          0.0           0.0  \n",
       "2010-01-06  86.314896  116074400       0.0          0.0           0.0  \n",
       "2010-01-07  86.679268  131091100       0.0          0.0           0.0  \n",
       "2010-01-08  86.967697  126402800       0.0          0.0           0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Prices - Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3812 entries, 2010-01-04 to 2025-02-27\n",
      "Data columns (total 48 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   (GLD, Open)           3812 non-null   float64\n",
      " 1   (GLD, High)           3812 non-null   float64\n",
      " 2   (GLD, Low)            3812 non-null   float64\n",
      " 3   (GLD, Close)          3812 non-null   float64\n",
      " 4   (GLD, Volume)         3812 non-null   int64  \n",
      " 5   (GLD, Dividends)      3812 non-null   float64\n",
      " 6   (GLD, Stock Splits)   3812 non-null   float64\n",
      " 7   (GLD, Capital Gains)  3812 non-null   float64\n",
      " 8   (AGG, Open)           3812 non-null   float64\n",
      " 9   (AGG, High)           3812 non-null   float64\n",
      " 10  (AGG, Low)            3812 non-null   float64\n",
      " 11  (AGG, Close)          3812 non-null   float64\n",
      " 12  (AGG, Volume)         3812 non-null   int64  \n",
      " 13  (AGG, Dividends)      3812 non-null   float64\n",
      " 14  (AGG, Stock Splits)   3812 non-null   float64\n",
      " 15  (AGG, Capital Gains)  3812 non-null   float64\n",
      " 16  (VNQ, Open)           3812 non-null   float64\n",
      " 17  (VNQ, High)           3812 non-null   float64\n",
      " 18  (VNQ, Low)            3812 non-null   float64\n",
      " 19  (VNQ, Close)          3812 non-null   float64\n",
      " 20  (VNQ, Volume)         3812 non-null   int64  \n",
      " 21  (VNQ, Dividends)      3812 non-null   float64\n",
      " 22  (VNQ, Stock Splits)   3812 non-null   float64\n",
      " 23  (VNQ, Capital Gains)  3812 non-null   float64\n",
      " 24  (VWO, Open)           3812 non-null   float64\n",
      " 25  (VWO, High)           3812 non-null   float64\n",
      " 26  (VWO, Low)            3812 non-null   float64\n",
      " 27  (VWO, Close)          3812 non-null   float64\n",
      " 28  (VWO, Volume)         3812 non-null   int64  \n",
      " 29  (VWO, Dividends)      3812 non-null   float64\n",
      " 30  (VWO, Stock Splits)   3812 non-null   float64\n",
      " 31  (VWO, Capital Gains)  3812 non-null   float64\n",
      " 32  (VEA, Open)           3812 non-null   float64\n",
      " 33  (VEA, High)           3812 non-null   float64\n",
      " 34  (VEA, Low)            3812 non-null   float64\n",
      " 35  (VEA, Close)          3812 non-null   float64\n",
      " 36  (VEA, Volume)         3812 non-null   int64  \n",
      " 37  (VEA, Dividends)      3812 non-null   float64\n",
      " 38  (VEA, Stock Splits)   3812 non-null   float64\n",
      " 39  (VEA, Capital Gains)  3812 non-null   float64\n",
      " 40  (SPY, Open)           3812 non-null   float64\n",
      " 41  (SPY, High)           3812 non-null   float64\n",
      " 42  (SPY, Low)            3812 non-null   float64\n",
      " 43  (SPY, Close)          3812 non-null   float64\n",
      " 44  (SPY, Volume)         3812 non-null   int64  \n",
      " 45  (SPY, Dividends)      3812 non-null   float64\n",
      " 46  (SPY, Stock Splits)   3812 non-null   float64\n",
      " 47  (SPY, Capital Gains)  3812 non-null   float64\n",
      "dtypes: float64(42), int64(6)\n",
      "memory usage: 1.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Prices - Column names and types:\n",
      "('GLD', 'Open') - <class 'tuple'>\n",
      "('GLD', 'High') - <class 'tuple'>\n",
      "('GLD', 'Low') - <class 'tuple'>\n",
      "('GLD', 'Close') - <class 'tuple'>\n",
      "('GLD', 'Volume') - <class 'tuple'>\n",
      "('GLD', 'Dividends') - <class 'tuple'>\n",
      "('GLD', 'Stock Splits') - <class 'tuple'>\n",
      "('GLD', 'Capital Gains') - <class 'tuple'>\n",
      "('AGG', 'Open') - <class 'tuple'>\n",
      "('AGG', 'High') - <class 'tuple'>\n",
      "('AGG', 'Low') - <class 'tuple'>\n",
      "('AGG', 'Close') - <class 'tuple'>\n",
      "('AGG', 'Volume') - <class 'tuple'>\n",
      "('AGG', 'Dividends') - <class 'tuple'>\n",
      "('AGG', 'Stock Splits') - <class 'tuple'>\n",
      "('AGG', 'Capital Gains') - <class 'tuple'>\n",
      "('VNQ', 'Open') - <class 'tuple'>\n",
      "('VNQ', 'High') - <class 'tuple'>\n",
      "('VNQ', 'Low') - <class 'tuple'>\n",
      "('VNQ', 'Close') - <class 'tuple'>\n",
      "('VNQ', 'Volume') - <class 'tuple'>\n",
      "('VNQ', 'Dividends') - <class 'tuple'>\n",
      "('VNQ', 'Stock Splits') - <class 'tuple'>\n",
      "('VNQ', 'Capital Gains') - <class 'tuple'>\n",
      "('VWO', 'Open') - <class 'tuple'>\n",
      "('VWO', 'High') - <class 'tuple'>\n",
      "('VWO', 'Low') - <class 'tuple'>\n",
      "('VWO', 'Close') - <class 'tuple'>\n",
      "('VWO', 'Volume') - <class 'tuple'>\n",
      "('VWO', 'Dividends') - <class 'tuple'>\n",
      "('VWO', 'Stock Splits') - <class 'tuple'>\n",
      "('VWO', 'Capital Gains') - <class 'tuple'>\n",
      "('VEA', 'Open') - <class 'tuple'>\n",
      "('VEA', 'High') - <class 'tuple'>\n",
      "('VEA', 'Low') - <class 'tuple'>\n",
      "('VEA', 'Close') - <class 'tuple'>\n",
      "('VEA', 'Volume') - <class 'tuple'>\n",
      "('VEA', 'Dividends') - <class 'tuple'>\n",
      "('VEA', 'Stock Splits') - <class 'tuple'>\n",
      "('VEA', 'Capital Gains') - <class 'tuple'>\n",
      "('SPY', 'Open') - <class 'tuple'>\n",
      "('SPY', 'High') - <class 'tuple'>\n",
      "('SPY', 'Low') - <class 'tuple'>\n",
      "('SPY', 'Close') - <class 'tuple'>\n",
      "('SPY', 'Volume') - <class 'tuple'>\n",
      "('SPY', 'Dividends') - <class 'tuple'>\n",
      "('SPY', 'Stock Splits') - <class 'tuple'>\n",
      "('SPY', 'Capital Gains') - <class 'tuple'>\n",
      "Date differences (frequency):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1 days    2984\n",
       "2 days      37\n",
       "3 days     686\n",
       "4 days     103\n",
       "5 days       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using '('GLD', 'Stock Splits')' as the ticker/symbol identifier column.\n",
      "Number of unique stocks: 1\n",
      "Sample ('GLD', 'Stock Splits') values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Stock Prices - First 5 rows:\")\n",
    "display(stock_prices.head())\n",
    "print(\"\\nStock Prices - Information:\")\n",
    "display(stock_prices.info())\n",
    "print(\"\\nStock Prices - Column names and types:\")\n",
    "for col in stock_prices.columns:\n",
    "    print(f\"{col} - {type(col)}\")\n",
    "check_data_frequency(stock_prices)\n",
    "\n",
    "# Determine if we have a ticker/symbol column\n",
    "def find_ticker_column(df):\n",
    "    ticker_col = None\n",
    "    # List of keywords to look for in column names\n",
    "    ticker_keywords = ['ticker', 'symbol', 'stock', 'asset', 'security']\n",
    "    \n",
    "    # Check for exact matches first\n",
    "    if 'ticker' in df.columns:\n",
    "        ticker_col = 'ticker'\n",
    "    elif 'symbol' in df.columns:\n",
    "        ticker_col = 'symbol'\n",
    "    else:\n",
    "        # Look for columns containing keywords, handling both string and tuple column names\n",
    "        for col in df.columns:\n",
    "            # For string column names\n",
    "            if isinstance(col, str) and any(keyword in col.lower() for keyword in ticker_keywords):\n",
    "                ticker_col = col\n",
    "                break\n",
    "            # For tuple column names, check each element in the tuple\n",
    "            elif isinstance(col, tuple):\n",
    "                for item in col:\n",
    "                    if isinstance(item, str) and any(keyword in item.lower() for keyword in ticker_keywords):\n",
    "                        ticker_col = col\n",
    "                        break\n",
    "                if ticker_col:  # Break out of outer loop if we found a match\n",
    "                    break\n",
    "    \n",
    "    if ticker_col:\n",
    "        print(f\"Using '{ticker_col}' as the ticker/symbol identifier column.\")\n",
    "    else:\n",
    "        print(\"No ticker/symbol column found. This might be data for a single stock or an index.\")\n",
    "    \n",
    "    return ticker_col\n",
    "\n",
    "# Find ticker column\n",
    "ticker_col = find_ticker_column(stock_prices)\n",
    "\n",
    "# Print stock identifiers if available\n",
    "if ticker_col:\n",
    "    print(f\"Number of unique stocks: {stock_prices[ticker_col].nunique()}\")\n",
    "    print(f\"Sample {ticker_col} values:\")\n",
    "    display(stock_prices[ticker_col].unique()[:10])\n",
    "else:\n",
    "    print(\"Processing as single time series data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02fdbb-db04-47da-9526-d0797257f02a",
   "metadata": {},
   "source": [
    "### 2.4 World Bank Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ef2891-1ae6-4ae6-bdf3-83fe9cee185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Bank Data - First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>GDP Growth</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Trade % GDP</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>2023</td>\n",
       "      <td>5.249558</td>\n",
       "      <td>0.234837</td>\n",
       "      <td>37.316771</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.950670</td>\n",
       "      <td>1.973576</td>\n",
       "      <td>38.351482</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.448469</td>\n",
       "      <td>0.981015</td>\n",
       "      <td>37.301991</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.238638</td>\n",
       "      <td>2.419422</td>\n",
       "      <td>34.754296</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>2019</td>\n",
       "      <td>5.950501</td>\n",
       "      <td>2.899234</td>\n",
       "      <td>35.890096</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  date  GDP Growth  Inflation  Trade % GDP  year\n",
       "0   China  2023    5.249558   0.234837    37.316771  2023\n",
       "1   China  2022    2.950670   1.973576    38.351482  2022\n",
       "2   China  2021    8.448469   0.981015    37.301991  2021\n",
       "3   China  2020    2.238638   2.419422    34.754296  2020\n",
       "4   China  2019    5.950501   2.899234    35.890096  2019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "World Bank Data - Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 70 entries, 0 to 269\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   country      70 non-null     object \n",
      " 1   date         70 non-null     object \n",
      " 2   GDP Growth   70 non-null     float64\n",
      " 3   Inflation    70 non-null     float64\n",
      " 4   Trade % GDP  70 non-null     float64\n",
      " 5   year         70 non-null     int64  \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 3.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "World Bank Data - Column names:\n",
      "['country', 'date', 'GDP Growth', 'Inflation', 'Trade % GDP', 'year']\n",
      "Potential date column found: date\n",
      "Sample values: ['2023', '2022', '2021', '2020', '2019']\n",
      "Date differences (frequency):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "-366 days    15\n",
       "-365 days    50\n",
       "4748 days     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"World Bank Data - First 5 rows:\")\n",
    "display(world_bank_data.head())\n",
    "print(\"\\nWorld Bank Data - Information:\")\n",
    "display(world_bank_data.info())\n",
    "\n",
    "# World Bank data is often formatted differently - let's examine the structure\n",
    "print(\"\\nWorld Bank Data - Column names:\")\n",
    "print(world_bank_data.columns.tolist())\n",
    "\n",
    "# Check if there's a date/year column\n",
    "date_col = None\n",
    "for col in world_bank_data.columns:\n",
    "    col_name = col if isinstance(col, str) else str(col)\n",
    "    if any(keyword in col_name.lower() for keyword in ['date', 'year', 'time', 'period']):\n",
    "        date_col = col\n",
    "        print(f\"Potential date column found: {col}\")\n",
    "        print(f\"Sample values: {world_bank_data[col].iloc[:5].tolist()}\")\n",
    "        break\n",
    "\n",
    "if date_col:\n",
    "    try:\n",
    "        # Try to convert to datetime for frequency analysis\n",
    "        world_bank_data_copy = world_bank_data.copy()\n",
    "        world_bank_data_copy[date_col] = pd.to_datetime(world_bank_data_copy[date_col])\n",
    "        check_data_frequency(world_bank_data_copy, date_column=date_col)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not convert World Bank date column to datetime: {e}\")\n",
    "        # If conversion fails, try checking if it's annual data with year values\n",
    "        if world_bank_data[date_col].dtype in ['int64', 'float64'] or world_bank_data[date_col].str.isnumeric().all():\n",
    "            print(\"Data appears to be annual with year values.\")\n",
    "else:\n",
    "    print(\"No obvious date column found. Examining shape of data instead.\")\n",
    "    print(f\"Number of rows: {world_bank_data.shape[0]}\")\n",
    "    print(f\"Number of columns: {world_bank_data.shape[1]}\")\n",
    "    \n",
    "    # Check if columns might be years (common in World Bank data)\n",
    "    numeric_cols = [col for col in world_bank_data.columns if isinstance(col, (int, float)) or \n",
    "                   (isinstance(col, str) and col.isdigit())]\n",
    "    if numeric_cols:\n",
    "        print(\"Some column names appear to be years:\")\n",
    "        print(sorted(numeric_cols)[:10])  # Show first 10 years\n",
    "        print(\"This suggests wide-format data with years as columns.\")\n",
    "        \n",
    "        # If needed, we can reshape to long format\n",
    "        print(\"\\nExample of how to reshape to long format:\")\n",
    "        print(\"world_bank_long = world_bank_data.melt(id_vars=['country', 'indicator'], var_name='year', value_name='value')\")\n",
    "        \n",
    "        # Try to identify ID columns (non-year columns)\n",
    "        id_cols = [col for col in world_bank_data.columns if col not in numeric_cols]\n",
    "        if id_cols:\n",
    "            print(\"\\nNon-year columns that could be identifiers:\")\n",
    "            print(id_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9e731-e8b7-4eb0-82f4-b3be13137b07",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d340749-14cc-4cde-8d9c-233b2da5b991",
   "metadata": {},
   "source": [
    "### 3.1 Time Series Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c737af5-20aa-4eec-8b14-c09a0a6da766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_time_series_data(dataframes, date_col='date', freq='M', methods=None, ticker_cols=None):\n",
    "    \"\"\"\n",
    "    Align multiple time series dataframes to a common frequency\n",
    "    \n",
    "    Args:\n",
    "        dataframes: List of dataframes to align\n",
    "        date_col: Name of the date column\n",
    "        freq: Target frequency ('D' for daily, 'W' for weekly, 'M' for monthly)\n",
    "        methods: List of methods to use for resampling each dataframe\n",
    "                ('mean', 'last', 'first', etc.)\n",
    "        ticker_cols: List of column names that identify individual assets in each dataframe\n",
    "                    (None for dataframes without asset identifiers)\n",
    "    \n",
    "    Returns:\n",
    "        List of aligned dataframes\n",
    "    \"\"\"\n",
    "    if methods is None:\n",
    "        methods = ['last'] * len(dataframes)\n",
    "    \n",
    "    if ticker_cols is None:\n",
    "        ticker_cols = [None] * len(dataframes)\n",
    "    \n",
    "    aligned_dfs = []\n",
    "    \n",
    "    for df, method, ticker_col in zip(dataframes, methods, ticker_cols):\n",
    "        # Make sure index is datetime\n",
    "        if date_col in df.columns:\n",
    "            df = df.set_index(date_col)\n",
    "        \n",
    "        # For stock data with multiple tickers, handle differently\n",
    "        if ticker_col and ticker_col in df.columns:\n",
    "            # Example: Process each ticker separately and then combine\n",
    "            tickers = df[ticker_col].unique()\n",
    "            aligned_ticker_dfs = []\n",
    "            \n",
    "            for ticker in tickers:\n",
    "                ticker_df = df[df[ticker_col] == ticker].copy()\n",
    "                # Resample ticker data\n",
    "                resampled = ticker_df.resample(freq).agg(method)\n",
    "                resampled[ticker_col] = ticker\n",
    "                aligned_ticker_dfs.append(resampled)\n",
    "            \n",
    "            aligned_df = pd.concat(aligned_ticker_dfs)\n",
    "        else:\n",
    "            # For single time series dataframes (economic indicators, factors)\n",
    "            aligned_df = df.resample(freq).agg(method)\n",
    "        \n",
    "        aligned_dfs.append(aligned_df)\n",
    "    \n",
    "    return aligned_dfs\n",
    "\n",
    "# Determine appropriate resampling methods for each dataset\n",
    "resample_methods = [\n",
    "    {'date': 'first', 'numerical_cols': 'last'},  # Economic indicators\n",
    "    {'date': 'first', 'numerical_cols': 'mean'},  # Fama-French\n",
    "    {'date': 'first', 'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'},  # Stock prices\n",
    "    {'date': 'first', 'numerical_cols': 'last'}   # World Bank data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08762131-06c7-42a3-85e2-0189e2d2a6cd",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24046c8-be28-4bea-8907-594b7b60037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, method='ffill'):\n",
    "    \"\"\"Fill missing values in the dataframe\"\"\"\n",
    "    if method == 'ffill':\n",
    "        return df.ffill()\n",
    "    elif method == 'bfill':\n",
    "        return df.bfill()\n",
    "    elif method == 'interpolate':\n",
    "        return df.interpolate(method='linear')\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb2ff6-f62a-45dc-969d-51c48f09e84d",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering for Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c6197e-1f1f-465a-ac70-5511fbd17b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_return_features(df, price_col='close', periods=[1, 5, 20, 60, 120, 252]):\n",
    "    \"\"\"\n",
    "    Calculate various return-based features\n",
    "    \n",
    "    Args:\n",
    "        df: Stock price dataframe\n",
    "        price_col: Column containing price data\n",
    "        periods: List of periods for calculating returns\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe with added return features\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Simple returns\n",
    "    for period in periods:\n",
    "        result[f'return_{period}d'] = result[price_col].pct_change(period)\n",
    "    \n",
    "    # Log returns (useful for mathematical operations)\n",
    "    result['log_return_1d'] = np.log(result[price_col] / result[price_col].shift(1))\n",
    "    \n",
    "    # Cumulative returns\n",
    "    result['cum_return_ytd'] = result.groupby([result.index.year, 'ticker'])[price_col].apply(\n",
    "        lambda x: x / x.iloc[0] - 1)\n",
    "    \n",
    "    # Rolling return metrics\n",
    "    result['rolling_mean_20d'] = result['return_1d'].rolling(window=20).mean()\n",
    "    result['rolling_std_20d'] = result['return_1d'].rolling(window=20).std()\n",
    "    \n",
    "    # Risk-adjusted return (Sharpe ratio proxy - without risk-free rate)\n",
    "    result['rolling_sharpe_20d'] = result['rolling_mean_20d'] / result['rolling_std_20d']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_volatility_features(df, return_col='return_1d', windows=[20, 60, 120]):\n",
    "    \"\"\"Calculate volatility-based features\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Historical volatility (annualized)\n",
    "    for window in windows:\n",
    "        result[f'volatility_{window}d'] = result[return_col].rolling(window=window).std() * np.sqrt(252)\n",
    "    \n",
    "    # Calculate high-low range volatility\n",
    "    if 'high' in result.columns and 'low' in result.columns:\n",
    "        result['daily_range'] = (result['high'] - result['low']) / result['close']\n",
    "        result['rolling_range_20d'] = result['daily_range'].rolling(window=20).mean()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_technical_indicators(df, close_col='close', high_col='high', low_col='low', volume_col='volume'):\n",
    "    \"\"\"Calculate common technical indicators\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for window in [20, 50, 200]:\n",
    "        result[f'ma_{window}d'] = result[close_col].rolling(window=window).mean()\n",
    "    \n",
    "    # MACD components\n",
    "    result['ema_12d'] = result[close_col].ewm(span=12, adjust=False).mean()\n",
    "    result['ema_26d'] = result[close_col].ewm(span=26, adjust=False).mean()\n",
    "    result['macd'] = result['ema_12d'] - result['ema_26d']\n",
    "    result['macd_signal'] = result['macd'].ewm(span=9, adjust=False).mean()\n",
    "    result['macd_hist'] = result['macd'] - result['macd_signal']\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    delta = result[close_col].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    rs = gain / loss.replace(0, np.nan)\n",
    "    result['rsi_14d'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    result['bb_middle_20d'] = result[close_col].rolling(window=20).mean()\n",
    "    result['bb_std_20d'] = result[close_col].rolling(window=20).std()\n",
    "    result['bb_upper_20d'] = result['bb_middle_20d'] + 2 * result['bb_std_20d']\n",
    "    result['bb_lower_20d'] = result['bb_middle_20d'] - 2 * result['bb_std_20d']\n",
    "    \n",
    "    # Relative volume\n",
    "    result['volume_ratio_20d'] = result[volume_col] / result[volume_col].rolling(window=20).mean()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_momentum_features(df, close_col='close', periods=[20, 60, 120, 252]):\n",
    "    \"\"\"Calculate momentum-based features\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Momentum (price change over period)\n",
    "    for period in periods:\n",
    "        result[f'momentum_{period}d'] = result[close_col].diff(period)\n",
    "    \n",
    "    # Rate of Change (percent price change over period)\n",
    "    for period in periods:\n",
    "        result[f'roc_{period}d'] = result[close_col].pct_change(period) * 100\n",
    "    \n",
    "    # Recent performance percentile (where current price ranks in its recent history)\n",
    "    for period in periods:\n",
    "        result[f'price_percentile_{period}d'] = result[close_col].rolling(period).apply(\n",
    "            lambda x: pd.Series(x).rank(pct=True).iloc[-1])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_drawdown_features(df, return_col='return_1d'):\n",
    "    \"\"\"Calculate drawdown-related features\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    result['cum_return'] = (1 + result[return_col]).cumprod()\n",
    "    \n",
    "    # Calculate running maximum\n",
    "    result['running_max'] = result['cum_return'].cummax()\n",
    "    \n",
    "    # Calculate drawdown\n",
    "    result['drawdown'] = result['cum_return'] / result['running_max'] - 1\n",
    "    \n",
    "    # Rolling maximum drawdown\n",
    "    result['max_drawdown_60d'] = result['drawdown'].rolling(window=60).min()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ce8f3-7cf0-4005-897d-d62669e57bf5",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering for Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a2ba70-d8e0-45e9-a57c-f72c3b099278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_economic_indicators_features(df):\n",
    "    \"\"\"Generate features from economic indicators\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Calculate changes\n",
    "    numeric_cols = result.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Percentage change\n",
    "        result[f'{col}_pct_change'] = result[col].pct_change()\n",
    "        \n",
    "        # Z-score (standardization)\n",
    "        result[f'{col}_zscore'] = (result[col] - result[col].rolling(window=60).mean()) / result[col].rolling(window=60).std()\n",
    "        \n",
    "        # Moving averages\n",
    "        result[f'{col}_ma_3m'] = result[col].rolling(window=3).mean()\n",
    "        result[f'{col}_ma_12m'] = result[col].rolling(window=12).mean()\n",
    "        \n",
    "        # Trend indicators (difference between short and long moving averages)\n",
    "        result[f'{col}_trend'] = result[f'{col}_ma_3m'] - result[f'{col}_ma_12m']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_yield_curve_features(df, columns=['yield_3m', 'yield_2y', 'yield_5y', 'yield_10y', 'yield_30y']):\n",
    "    \"\"\"Calculate yield curve related features\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Ensure we have required columns\n",
    "    if all(col in df.columns for col in columns):\n",
    "        # Term spreads (differences between yields of different maturities)\n",
    "        result['term_spread_10y_3m'] = result['yield_10y'] - result['yield_3m']\n",
    "        result['term_spread_10y_2y'] = result['yield_10y'] - result['yield_2y']\n",
    "        result['term_spread_30y_10y'] = result['yield_30y'] - result['yield_10y']\n",
    "        \n",
    "        # Yield curve steepness (difference between longest and shortest yield)\n",
    "        result['yield_curve_steepness'] = result['yield_30y'] - result['yield_3m']\n",
    "        \n",
    "        # Yield curve curvature\n",
    "        result['yield_curve_curvature'] = (result['yield_5y'] * 2) - result['yield_2y'] - result['yield_10y']\n",
    "        \n",
    "        # Moving averages and trends of spreads\n",
    "        result['term_spread_10y_3m_ma_12m'] = result['term_spread_10y_3m'].rolling(window=12).mean()\n",
    "        result['term_spread_10y_3m_trend'] = result['term_spread_10y_3m'] - result['term_spread_10y_3m_ma_12m']\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a5c64-e83b-420a-8d66-137ba0d0e9e8",
   "metadata": {},
   "source": [
    "## 6. Market Regime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44918e44-5a42-4d8f-9655-b7428407bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_market_regime_features(stock_data, economic_data, fama_french_data, ticker_col=None):\n",
    "    \"\"\"Create features for market regime classification\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    stock_data_copy = stock_data.copy()\n",
    "    \n",
    "    # Check if we need to handle multiple tickers\n",
    "    if ticker_col and ticker_col in stock_data_copy.columns:\n",
    "        # Create market aggregate by averaging across tickers\n",
    "        aggregation_cols = {\n",
    "            'return_1d': 'mean',\n",
    "            'volatility_20d': 'mean',\n",
    "            'drawdown': 'mean'\n",
    "        }\n",
    "        \n",
    "        # Add volume ratio if it exists\n",
    "        if 'volume_ratio_20d' in stock_data_copy.columns:\n",
    "            aggregation_cols['volume_ratio_20d'] = 'mean'\n",
    "        \n",
    "        # Group by date and aggregate\n",
    "        market_data = stock_data_copy.groupby(stock_data_copy.index).agg(aggregation_cols)\n",
    "    else:\n",
    "        # Single time series, just use it directly as market data\n",
    "        market_data = stock_data_copy\n",
    "    \n",
    "    # Rename columns to indicate market level\n",
    "    rename_dict = {}\n",
    "    if 'return_1d' in market_data.columns:\n",
    "        rename_dict['return_1d'] = 'market_return'\n",
    "    if 'volatility_20d' in market_data.columns:\n",
    "        rename_dict['volatility_20d'] = 'market_volatility'\n",
    "    if 'volume_ratio_20d' in market_data.columns:\n",
    "        rename_dict['volume_ratio_20d'] = 'market_volume_ratio'\n",
    "    if 'drawdown' in market_data.columns:\n",
    "        rename_dict['drawdown'] = 'market_drawdown'\n",
    "    \n",
    "    market_data = market_data.rename(columns=rename_dict)\n",
    "    \n",
    "    # Make sure we have market_return for further analysis\n",
    "    if 'market_return' not in market_data.columns:\n",
    "        if 'return_1d' in stock_data_copy.columns:\n",
    "            market_data['market_return'] = stock_data_copy['return_1d']\n",
    "        else:\n",
    "            print(\"Warning: No return data found. Using random values for demonstration.\")\n",
    "            market_data['market_return'] = np.random.normal(0.0001, 0.01, size=len(market_data))\n",
    "    \n",
    "    # Make sure we have market_volatility for further analysis\n",
    "    if 'market_volatility' not in market_data.columns:\n",
    "        if 'volatility_20d' in stock_data_copy.columns:\n",
    "            market_data['market_volatility'] = stock_data_copy['volatility_20d']\n",
    "        else:\n",
    "            print(\"Warning: No volatility data found. Calculating from returns.\")\n",
    "            market_data['market_volatility'] = market_data['market_return'].rolling(window=20).std() * np.sqrt(252)\n",
    "    \n",
    "    # Add rolling statistics\n",
    "    market_data['rolling_return_20d'] = market_data['market_return'].rolling(window=20).mean() * 20  # Approx monthly return\n",
    "    market_data['rolling_return_60d'] = market_data['market_return'].rolling(window=60).mean() * 60  # Approx quarterly return\n",
    "    \n",
    "    # Volatility regime features (using ffill to handle NaNs)\n",
    "    market_data['market_volatility_filled'] = market_data['market_volatility'].fillna(method='ffill')\n",
    "    \n",
    "    # Check if we have enough data for quantiles\n",
    "    if len(market_data) >= 4:  # Need at least 4 points for 4 quantiles\n",
    "        try:\n",
    "            market_data['volatility_regime'] = pd.qcut(\n",
    "                market_data['market_volatility_filled'], \n",
    "                q=4, \n",
    "                labels=['low', 'medium-low', 'medium-high', 'high']\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not create volatility regimes: {e}\")\n",
    "            # Create a simplified version with just high/low split\n",
    "            median_vol = market_data['market_volatility_filled'].median()\n",
    "            market_data['volatility_regime'] = np.where(\n",
    "                market_data['market_volatility_filled'] > median_vol, \n",
    "                'high', \n",
    "                'low'\n",
    "            )\n",
    "    else:\n",
    "        print(\"Warning: Not enough data for volatility regime classification.\")\n",
    "        market_data['volatility_regime'] = 'undefined'\n",
    "    \n",
    "    # Trend regime features (simplified version)\n",
    "    market_data['market_ma_20d'] = market_data['market_return'].rolling(window=20).mean()\n",
    "    \n",
    "    # Use a smaller window if we don't have enough data\n",
    "    ma_long_window = min(100, max(30, len(market_data) // 3))\n",
    "    market_data['market_ma_long'] = market_data['market_return'].rolling(window=ma_long_window).mean()\n",
    "    market_data['trend_indicator'] = np.where(\n",
    "        market_data['market_ma_20d'] > market_data['market_ma_long'], \n",
    "        1, \n",
    "        -1\n",
    "    )\n",
    "    \n",
    "    # Join with economic indicators if available\n",
    "    if economic_data is not None and not economic_data.empty:\n",
    "        regime_features = market_data.join(economic_data, how='left')\n",
    "    else:\n",
    "        regime_features = market_data\n",
    "    \n",
    "    # Add Fama-French factors if available\n",
    "    if fama_french_data is not None and not fama_french_data.empty:\n",
    "        # Check if the required columns exist\n",
    "        ff_cols = [col for col in ['SMB', 'HML'] if col in fama_french_data.columns]\n",
    "        \n",
    "        if ff_cols:\n",
    "            regime_features = regime_features.join(fama_french_data[ff_cols], how='left')\n",
    "            \n",
    "            # Calculate rolling factor performance\n",
    "            for factor in ff_cols:\n",
    "                regime_features[f'{factor}_60d'] = fama_french_data[factor].rolling(window=60).mean() * 60\n",
    "                regime_features[f'{factor}_regime'] = np.sign(regime_features[f'{factor}_60d'])\n",
    "    \n",
    "    # Basic market regime classification\n",
    "    if all(col in regime_features.columns for col in ['market_volatility', 'market_return']):\n",
    "        # Use 75th percentile for volatility threshold\n",
    "        vol_threshold = regime_features['market_volatility'].quantile(0.75)\n",
    "        \n",
    "        conditions = [\n",
    "            (regime_features['market_volatility'] > vol_threshold) & \n",
    "            (regime_features['market_return'] < 0),\n",
    "            \n",
    "            (regime_features['market_volatility'] <= vol_threshold) & \n",
    "            (regime_features['market_return'] < 0),\n",
    "            \n",
    "            (regime_features['market_volatility'] > vol_threshold) & \n",
    "            (regime_features['market_return'] >= 0),\n",
    "            \n",
    "            (regime_features['market_volatility'] <= vol_threshold) & \n",
    "            (regime_features['market_return'] >= 0)\n",
    "        ]\n",
    "        \n",
    "        choices = ['bear_volatile', 'bear_stable', 'bull_volatile', 'bull_stable']\n",
    "        regime_features['market_regime_basic'] = np.select(conditions, choices, default='undefined')\n",
    "    \n",
    "    return regime_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db56197-fc00-4923-9ced-86d2e078a2ce",
   "metadata": {},
   "source": [
    "## 7. Apply Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89db9638-8d7d-4585-9886-43ad3e10caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for stock data...\n",
      "Using '('GLD', 'Stock Splits')' as the ticker/symbol identifier column.\n",
      "Using '('GLD', 'Close')' as the close price column.\n",
      "Identified columns: {'close': ('GLD', 'Close'), 'high': ('GLD', 'High'), 'low': ('GLD', 'Low'), 'volume': ('GLD', 'Volume')}\n",
      "Engineering features for economic indicators...\n",
      "\n",
      "Analyzing stock data structure:\n",
      "Column index levels: 2\n",
      "Index type: <class 'pandas.core.indexes.multi.MultiIndex'>\n",
      "Detected MultiIndex columns. Restructuring data...\n",
      "Found 46 feature columns and 48 price columns\n",
      "Using ('SPY', 'Close') as market price\n",
      "Created market regime features DataFrame with shape: (3812, 41)\n",
      "Columns: ['market_return', 'market_volatility', 'market_drawdown', 'market_rsi', 'market_volume_ratio', 'rolling_return_20d', 'rolling_return_60d', 'market_ma_20d', 'market_ma_long', 'trend_indicator']...\n"
     ]
    }
   ],
   "source": [
    "# Check if required columns exist and identify column names\n",
    "def identify_price_columns(df):\n",
    "    \"\"\"Identify price and volume columns in the dataframe\"\"\"\n",
    "    col_mapping = {}\n",
    "    \n",
    "    # Helper function to check if a column name (string or tuple) contains a keyword\n",
    "    def column_contains_keyword(col, keyword):\n",
    "        if isinstance(col, str):\n",
    "            return keyword.lower() in col.lower()\n",
    "        elif isinstance(col, tuple):\n",
    "            return any(isinstance(item, str) and keyword.lower() in item.lower() for item in col)\n",
    "        return False\n",
    "    \n",
    "    # Look for close price column\n",
    "    close_candidates = [\n",
    "        col for col in df.columns if column_contains_keyword(col, 'close') or \n",
    "                                    column_contains_keyword(col, 'price') or \n",
    "                                    column_contains_keyword(col, 'adj')\n",
    "    ]\n",
    "    \n",
    "    if close_candidates:\n",
    "        col_mapping['close'] = close_candidates[0]\n",
    "        print(f\"Using '{close_candidates[0]}' as the close price column.\")\n",
    "    else:\n",
    "        # If no obvious price column, use the first numeric column\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            col_mapping['close'] = numeric_cols[0]\n",
    "            print(f\"Using '{numeric_cols[0]}' as the price column (fallback).\")\n",
    "        else:\n",
    "            print(\"Warning: No suitable price column found.\")\n",
    "            col_mapping['close'] = df.columns[0]  # Last resort fallback\n",
    "    \n",
    "    # Look for high price column\n",
    "    high_candidates = [col for col in df.columns if column_contains_keyword(col, 'high')]\n",
    "    if high_candidates:\n",
    "        col_mapping['high'] = high_candidates[0]\n",
    "    else:\n",
    "        col_mapping['high'] = col_mapping.get('close')  # Fallback to close price\n",
    "    \n",
    "    # Look for low price column\n",
    "    low_candidates = [col for col in df.columns if column_contains_keyword(col, 'low')]\n",
    "    if low_candidates:\n",
    "        col_mapping['low'] = low_candidates[0]\n",
    "    else:\n",
    "        col_mapping['low'] = col_mapping.get('close')  # Fallback to close price\n",
    "    \n",
    "    # Look for volume column\n",
    "    volume_candidates = [\n",
    "        col for col in df.columns if column_contains_keyword(col, 'volume') or \n",
    "                                    column_contains_keyword(col, 'vol')\n",
    "    ]\n",
    "    \n",
    "    if volume_candidates:\n",
    "        col_mapping['volume'] = volume_candidates[0]\n",
    "    else:\n",
    "        # If no volume column, create a dummy constant volume\n",
    "        print(\"Warning: No volume column found. Creating dummy volume.\")\n",
    "        df['dummy_volume'] = 1\n",
    "        col_mapping['volume'] = 'dummy_volume'\n",
    "    \n",
    "    return col_mapping\n",
    "\n",
    "# Process stock data\n",
    "print(\"Engineering features for stock data...\")\n",
    "stock_features = stock_prices.copy()\n",
    "\n",
    "# Find ticker column if it exists\n",
    "ticker_col = find_ticker_column(stock_features)\n",
    "\n",
    "# Identify price columns\n",
    "price_cols = identify_price_columns(stock_features)\n",
    "print(f\"Identified columns: {price_cols}\")\n",
    "\n",
    "# Apply feature engineering with identified columns\n",
    "\n",
    "# Define a modified version of calculate_return_features that supports ticker_col and tuple columns\n",
    "def calculate_return_features_with_ticker(df, price_col='close', periods=[1, 5, 20, 60, 120, 252], ticker_col=None):\n",
    "    \"\"\"\n",
    "    Calculate various return-based features with support for ticker column and tuple columns\n",
    "    \n",
    "    Args:\n",
    "        df: Stock price dataframe\n",
    "        price_col: Column containing price data\n",
    "        periods: List of periods for calculating returns\n",
    "        ticker_col: Column with ticker/symbol information (if any)\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe with added return features\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Simple returns\n",
    "    for period in periods:\n",
    "        result[f'return_{period}d'] = result[price_col].pct_change(period)\n",
    "    \n",
    "    # Log returns (useful for mathematical operations)\n",
    "    result['log_return_1d'] = np.log(result[price_col] / result[price_col].shift(1))\n",
    "    \n",
    "    # Cumulative returns - handle cases with and without ticker column\n",
    "    # Without using groupby with tuple columns which causes errors\n",
    "    try:\n",
    "        # Add a year column for grouping\n",
    "        result['_year'] = result.index.year\n",
    "        \n",
    "        # Calculate cumulative returns for each year\n",
    "        # First, identify year boundaries\n",
    "        year_starts = result['_year'] != result['_year'].shift(1)\n",
    "        # Create a cumulative return that resets at the start of each year\n",
    "        result['_cum_return_base'] = result[price_col] / result[price_col].shift(1)\n",
    "        result.loc[year_starts, '_cum_return_base'] = 1.0\n",
    "        # Calculate cumulative product\n",
    "        result['cum_return_ytd'] = result['_cum_return_base'].cumprod() - 1\n",
    "        \n",
    "        # Clean up temporary columns\n",
    "        result = result.drop(columns=['_year', '_cum_return_base'])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error calculating cumulative returns: {e}\")\n",
    "        result['cum_return_ytd'] = np.nan\n",
    "    \n",
    "    # Rolling return metrics\n",
    "    result['rolling_mean_20d'] = result['return_1d'].rolling(window=20).mean()\n",
    "    result['rolling_std_20d'] = result['return_1d'].rolling(window=20).std()\n",
    "    \n",
    "    # Risk-adjusted return (Sharpe ratio proxy - without risk-free rate)\n",
    "    result['rolling_sharpe_20d'] = result['rolling_mean_20d'] / result['rolling_std_20d']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Use the new function instead\n",
    "stock_features = calculate_return_features_with_ticker(\n",
    "    stock_features, \n",
    "    price_col=price_cols['close'],\n",
    "    ticker_col=ticker_col\n",
    ")\n",
    "\n",
    "# Define an updated volatility features function that accepts all needed parameters\n",
    "def calculate_volatility_features_enhanced(df, return_col='return_1d', windows=[20, 60, 120], high_col=None, low_col=None, close_col=None):\n",
    "    \"\"\"\n",
    "    Calculate volatility-based features with enhanced parameter support\n",
    "    \n",
    "    Args:\n",
    "        df: Stock price dataframe\n",
    "        return_col: Column containing return data\n",
    "        windows: List of windows for rolling calculations\n",
    "        high_col: Column containing high price data (optional)\n",
    "        low_col: Column containing low price data (optional)\n",
    "        close_col: Column containing close price data (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe with added volatility features\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Check if the return column exists\n",
    "    if return_col not in result.columns:\n",
    "        print(f\"Warning: '{return_col}' column not found. Creating it from close prices.\")\n",
    "        if close_col and close_col in result.columns:\n",
    "            result[return_col] = result[close_col].pct_change()\n",
    "        else:\n",
    "            # Use the first numeric column if no specific column is available\n",
    "            numeric_cols = result.select_dtypes(include=['number']).columns\n",
    "            if len(numeric_cols) > 0:\n",
    "                print(f\"Using '{numeric_cols[0]}' to calculate returns.\")\n",
    "                result[return_col] = result[numeric_cols[0]].pct_change()\n",
    "            else:\n",
    "                print(\"Error: No numeric columns available for return calculation.\")\n",
    "                return result\n",
    "    \n",
    "    # Historical volatility (annualized)\n",
    "    for window in windows:\n",
    "        result[f'volatility_{window}d'] = result[return_col].rolling(window=window).std() * np.sqrt(252)\n",
    "    \n",
    "    # Calculate high-low range volatility if we have the necessary columns\n",
    "    if high_col and low_col and close_col and all(col in result.columns for col in [high_col, low_col, close_col]):\n",
    "        result['daily_range'] = (result[high_col] - result[low_col]) / result[close_col]\n",
    "        result['rolling_range_20d'] = result['daily_range'].rolling(window=20).mean()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Use the enhanced version\n",
    "stock_features = calculate_volatility_features_enhanced(\n",
    "    stock_features,\n",
    "    return_col='return_1d',\n",
    "    high_col=price_cols['high'],\n",
    "    low_col=price_cols['low'],\n",
    "    close_col=price_cols['close']\n",
    ")\n",
    "\n",
    "# Define an enhanced technical indicators function\n",
    "def calculate_technical_indicators_enhanced(df, close_col='close', high_col='high', low_col='low', volume_col='volume'):\n",
    "    \"\"\"Calculate common technical indicators with enhanced parameter support\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for window in [20, 50, 200]:\n",
    "        result[f'ma_{window}d'] = result[close_col].rolling(window=window).mean()\n",
    "    \n",
    "    # MACD components\n",
    "    result['ema_12d'] = result[close_col].ewm(span=12, adjust=False).mean()\n",
    "    result['ema_26d'] = result[close_col].ewm(span=26, adjust=False).mean()\n",
    "    result['macd'] = result['ema_12d'] - result['ema_26d']\n",
    "    result['macd_signal'] = result['macd'].ewm(span=9, adjust=False).mean()\n",
    "    result['macd_hist'] = result['macd'] - result['macd_signal']\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    delta = result[close_col].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    rs = gain / loss.replace(0, np.nan)\n",
    "    result['rsi_14d'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    result['bb_middle_20d'] = result[close_col].rolling(window=20).mean()\n",
    "    result['bb_std_20d'] = result[close_col].rolling(window=20).std()\n",
    "    result['bb_upper_20d'] = result['bb_middle_20d'] + 2 * result['bb_std_20d']\n",
    "    result['bb_lower_20d'] = result['bb_middle_20d'] - 2 * result['bb_std_20d']\n",
    "    \n",
    "    # Relative volume if volume column is available\n",
    "    if volume_col in result.columns:\n",
    "        result['volume_ratio_20d'] = result[volume_col] / result[volume_col].rolling(window=20).mean()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Use the enhanced version\n",
    "stock_features = calculate_technical_indicators_enhanced(\n",
    "    stock_features, \n",
    "    close_col=price_cols['close'],\n",
    "    high_col=price_cols['high'],\n",
    "    low_col=price_cols['low'],\n",
    "    volume_col=price_cols['volume']\n",
    ")\n",
    "\n",
    "# Define an enhanced momentum features function\n",
    "def calculate_momentum_features_enhanced(df, close_col='close', periods=[20, 60, 120, 252]):\n",
    "    \"\"\"Calculate momentum-based features with enhanced parameter support\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Momentum (price change over period)\n",
    "    for period in periods:\n",
    "        result[f'momentum_{period}d'] = result[close_col].diff(period)\n",
    "    \n",
    "    # Rate of Change (percent price change over period)\n",
    "    for period in periods:\n",
    "        result[f'roc_{period}d'] = result[close_col].pct_change(period) * 100\n",
    "    \n",
    "    # Recent performance percentile (where current price ranks in its recent history)\n",
    "    for period in periods:\n",
    "        result[f'price_percentile_{period}d'] = result[close_col].rolling(period).apply(\n",
    "            lambda x: pd.Series(x).rank(pct=True).iloc[-1])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Use the enhanced version  \n",
    "stock_features = calculate_momentum_features_enhanced(stock_features, close_col=price_cols['close'])\n",
    "stock_features = calculate_drawdown_features(stock_features, return_col='return_1d')\n",
    "\n",
    "# Process economic indicators\n",
    "print(\"Engineering features for economic indicators...\")\n",
    "economic_features = calculate_economic_indicators_features(economic_indicators)\n",
    "economic_features = calculate_yield_curve_features(economic_features)\n",
    "\n",
    "# Define an enhanced version of the market regime features function\n",
    "def engineer_market_regime_features_enhanced(stock_data, economic_data, fama_french_data, ticker_col=None):\n",
    "    \"\"\"Create features for market regime classification with enhanced flexibility for MultiIndex dataframes\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    stock_data_copy = stock_data.copy()\n",
    "    \n",
    "    # Print column information\n",
    "    print(\"\\nAnalyzing stock data structure:\")\n",
    "    print(f\"Column index levels: {stock_data_copy.columns.nlevels}\")\n",
    "    print(f\"Index type: {type(stock_data_copy.columns)}\")\n",
    "    \n",
    "    # Handle MultiIndex columns\n",
    "    if isinstance(stock_data_copy.columns, pd.MultiIndex):\n",
    "        print(\"Detected MultiIndex columns. Restructuring data...\")\n",
    "        \n",
    "        # Identify features (columns with empty second level)\n",
    "        feature_cols = [col for col in stock_data_copy.columns if col[1] == '']\n",
    "        price_cols = [col for col in stock_data_copy.columns if col[1] != '']\n",
    "        \n",
    "        print(f\"Found {len(feature_cols)} feature columns and {len(price_cols)} price columns\")\n",
    "        \n",
    "        # Select only SPY (or another main index) close price for market representation\n",
    "        market_tickers = ['SPY', 'IVV', '^GSPC', '^SPX']  # Different representations of S&P 500\n",
    "        market_ticker = None\n",
    "        \n",
    "        for ticker in market_tickers:\n",
    "            market_close_candidates = [(t, c) for t, c in price_cols if t == ticker and 'close' in c.lower()]\n",
    "            if market_close_candidates:\n",
    "                market_ticker = ticker\n",
    "                market_close = market_close_candidates[0]\n",
    "                print(f\"Using {market_close} as market price\")\n",
    "                break\n",
    "        \n",
    "        if not market_ticker:\n",
    "            # If no S&P 500 representation, use the first ticker's close price\n",
    "            first_ticker = price_cols[0][0]\n",
    "            market_close_candidates = [(t, c) for t, c in price_cols if t == first_ticker and 'close' in c.lower()]\n",
    "            if market_close_candidates:\n",
    "                market_close = market_close_candidates[0]\n",
    "                print(f\"Using {market_close} as market price (fallback)\")\n",
    "            else:\n",
    "                # Last resort, use the first price column\n",
    "                market_close = price_cols[0]\n",
    "                print(f\"Using {market_close} as market price (last resort)\")\n",
    "        \n",
    "        # Create a simplified DataFrame with just market data and features\n",
    "        # First, let's extract just the needed feature columns\n",
    "        market_features = pd.DataFrame(index=stock_data_copy.index)\n",
    "        \n",
    "        # Add market return if it exists\n",
    "        if ('return_1d', '') in stock_data_copy.columns:\n",
    "            market_features['market_return'] = stock_data_copy[('return_1d', '')]\n",
    "        else:\n",
    "            # Calculate market return from price\n",
    "            market_features['market_return'] = stock_data_copy[market_close].pct_change()\n",
    "        \n",
    "        # Add market volatility if it exists\n",
    "        if ('volatility_20d', '') in stock_data_copy.columns:\n",
    "            market_features['market_volatility'] = stock_data_copy[('volatility_20d', '')]\n",
    "        else:\n",
    "            # Calculate market volatility from return\n",
    "            market_features['market_volatility'] = market_features['market_return'].rolling(window=20).std() * np.sqrt(252)\n",
    "        \n",
    "        # Add other useful features if they exist\n",
    "        if ('drawdown', '') in stock_data_copy.columns:\n",
    "            market_features['market_drawdown'] = stock_data_copy[('drawdown', '')]\n",
    "        \n",
    "        if ('rsi_14d', '') in stock_data_copy.columns:\n",
    "            market_features['market_rsi'] = stock_data_copy[('rsi_14d', '')]\n",
    "        \n",
    "        if ('volume_ratio_20d', '') in stock_data_copy.columns:\n",
    "            market_features['market_volume_ratio'] = stock_data_copy[('volume_ratio_20d', '')]\n",
    "        \n",
    "        # Use this simplified DataFrame for further calculations\n",
    "        market_data = market_features\n",
    "    else:\n",
    "        # For non-MultiIndex, use the same approach as before\n",
    "        print(\"Using standard column structure\")\n",
    "        \n",
    "        # Define aggregation columns\n",
    "        aggregation_cols = {}\n",
    "        if 'return_1d' in stock_data_copy.columns:\n",
    "            aggregation_cols['return_1d'] = 'mean'\n",
    "        if 'volatility_20d' in stock_data_copy.columns:\n",
    "            aggregation_cols['volatility_20d'] = 'mean'\n",
    "        if 'volume_ratio_20d' in stock_data_copy.columns:\n",
    "            aggregation_cols['volume_ratio_20d'] = 'mean'\n",
    "        if 'drawdown' in stock_data_copy.columns:\n",
    "            aggregation_cols['drawdown'] = 'mean'\n",
    "        \n",
    "        # Create market data\n",
    "        if aggregation_cols:\n",
    "            if ticker_col and ticker_col in stock_data_copy.columns:\n",
    "                try:\n",
    "                    market_data = stock_data_copy.groupby(stock_data_copy.index).agg(aggregation_cols)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during aggregation: {e}\")\n",
    "                    market_data = stock_data_copy.copy()\n",
    "            else:\n",
    "                market_data = stock_data_copy\n",
    "        else:\n",
    "            market_data = stock_data_copy\n",
    "    \n",
    "    # Add rolling statistics \n",
    "    if 'market_return' in market_data.columns:\n",
    "        try:\n",
    "            market_data['rolling_return_20d'] = market_data['market_return'].rolling(window=20).mean() * 20  # Approx monthly return\n",
    "            market_data['rolling_return_60d'] = market_data['market_return'].rolling(window=60).mean() * 60  # Approx quarterly return\n",
    "            \n",
    "            # Trend regime features\n",
    "            market_data['market_ma_20d'] = market_data['market_return'].rolling(window=20).mean()\n",
    "            ma_long_window = min(100, max(30, len(market_data) // 3))\n",
    "            market_data['market_ma_long'] = market_data['market_return'].rolling(window=ma_long_window).mean()\n",
    "            market_data['trend_indicator'] = np.where(\n",
    "                market_data['market_ma_20d'] > market_data['market_ma_long'], \n",
    "                1, \n",
    "                -1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating return metrics: {e}\")\n",
    "    \n",
    "    # Join with economic indicators if available\n",
    "    if economic_data is not None and not economic_data.empty:\n",
    "        try:\n",
    "            # Check if economic data has a different index level\n",
    "            if (isinstance(economic_data.index, pd.MultiIndex) and \n",
    "                not isinstance(market_data.index, pd.MultiIndex)):\n",
    "                # Simplify economic_data index\n",
    "                economic_data_simplified = economic_data.copy()\n",
    "                if isinstance(economic_data_simplified.index, pd.MultiIndex):\n",
    "                    economic_data_simplified.index = economic_data_simplified.index.get_level_values(0)\n",
    "                regime_features = market_data.join(economic_data_simplified, how='left')\n",
    "            elif (not isinstance(economic_data.index, pd.MultiIndex) and \n",
    "                  isinstance(market_data.index, pd.MultiIndex)):\n",
    "                # Simplify market_data index\n",
    "                market_data_simplified = market_data.copy()\n",
    "                if isinstance(market_data_simplified.index, pd.MultiIndex):\n",
    "                    market_data_simplified.index = market_data_simplified.index.get_level_values(0)\n",
    "                regime_features = market_data_simplified.join(economic_data, how='left')\n",
    "            else:\n",
    "                # Both have same index structure\n",
    "                regime_features = market_data.join(economic_data, how='left')\n",
    "        except Exception as e:\n",
    "            print(f\"Error joining economic data: {e}\")\n",
    "            print(\"Using market data without economic indicators\")\n",
    "            regime_features = market_data\n",
    "    else:\n",
    "        regime_features = market_data\n",
    "    \n",
    "    # Basic market regime classification\n",
    "    if 'market_volatility' in regime_features.columns and 'market_return' in regime_features.columns:\n",
    "        try:\n",
    "            # Use 75th percentile for volatility threshold\n",
    "            vol_threshold = regime_features['market_volatility'].quantile(0.75)\n",
    "            \n",
    "            conditions = [\n",
    "                (regime_features['market_volatility'] > vol_threshold) & \n",
    "                (regime_features['market_return'] < 0),\n",
    "                \n",
    "                (regime_features['market_volatility'] <= vol_threshold) & \n",
    "                (regime_features['market_return'] < 0),\n",
    "                \n",
    "                (regime_features['market_volatility'] > vol_threshold) & \n",
    "                (regime_features['market_return'] >= 0),\n",
    "                \n",
    "                (regime_features['market_volatility'] <= vol_threshold) & \n",
    "                (regime_features['market_return'] >= 0)\n",
    "            ]\n",
    "            \n",
    "            choices = ['bear_volatile', 'bear_stable', 'bull_volatile', 'bull_stable']\n",
    "            regime_features['market_regime_basic'] = np.select(conditions, choices, default='undefined')\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating market regime classification: {e}\")\n",
    "    \n",
    "    print(f\"Created market regime features DataFrame with shape: {regime_features.shape}\")\n",
    "    print(f\"Columns: {regime_features.columns.tolist()[:10]}...\")\n",
    "    \n",
    "    return regime_features\n",
    "    \n",
    "# Use the enhanced version\n",
    "market_regime_features = engineer_market_regime_features_enhanced(\n",
    "    stock_features, economic_features, fama_french_factors, ticker_col=ticker_col\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cee933-c327-4bc7-ba4e-76558160183a",
   "metadata": {},
   "source": [
    "## 8. Feature Selection and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5d8f1-6b55-418f-b074-a343eb6a2fcb",
   "metadata": {},
   "source": [
    "### 8.1 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3ce2db-d496-406e-946b-ff680d3a1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_correlations(df, target_col=None, threshold=0.7):\n",
    "    \"\"\"Analyze correlations between features\"\"\"\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df.select_dtypes(include=['number']).corr()\n",
    "    \n",
    "    # Plot the correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated feature pairs\n",
    "    high_corr_features = []\n",
    "    \n",
    "    # Get the upper triangle of the correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find features with correlation greater than threshold\n",
    "    for col in upper.columns:\n",
    "        high_corr = upper[col][abs(upper[col]) > threshold].index.tolist()\n",
    "        for feature in high_corr:\n",
    "            high_corr_features.append((col, feature, upper[col][feature]))\n",
    "    \n",
    "    # Sort by correlation value\n",
    "    high_corr_features.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    \n",
    "    print(f\"Highly correlated feature pairs (|r| > {threshold}):\")\n",
    "    for feat1, feat2, corr in high_corr_features:\n",
    "        print(f\"{feat1} - {feat2}: {corr:.4f}\")\n",
    "    \n",
    "    # If target column is specified, show correlation with target\n",
    "    if target_col and target_col in corr_matrix.columns:\n",
    "        target_corr = corr_matrix[target_col].sort_values(ascending=False)\n",
    "        print(f\"\\nFeature correlations with {target_col}:\")\n",
    "        print(target_corr)\n",
    "    \n",
    "    return high_corr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4445b-fdcf-4122-9415-2499af1e4535",
   "metadata": {},
   "source": [
    "### 8.2 Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc7fb20-74a1-4fa2-8549-985a2365e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(df, target_col, top_n=20):\n",
    "    \"\"\"Analyze feature importance using a simple model\"\"\"\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df.select_dtypes(include=['number']).drop(columns=[target_col], errors='ignore')\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Handle missing values for this analysis\n",
    "    X = X.fillna(X.mean())\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Train a simple random forest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': df.select_dtypes(include=['number']).drop(columns=[target_col], errors='ignore').columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot top features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(top_n))\n",
    "    plt.title(f'Top {top_n} Features by Importance for {target_col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6058de1-ac64-4124-965e-8ee5332cbc5e",
   "metadata": {},
   "source": [
    "## 9. Save Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc26ec82-854c-4096-899a-8b48f82ccf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stock_features.parquet - Shape: (3812, 94)\n",
      "Saved economic_features.parquet - Shape: (4005, 30)\n",
      "Saved market_regime_features.parquet - Shape: (3812, 41)\n"
     ]
    }
   ],
   "source": [
    "# Save the engineered features\n",
    "def save_features(dfs, filenames):\n",
    "    \"\"\"Save processed dataframes to parquet files\"\"\"\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        filepath = PROCESSED_DATA_PATH / filename\n",
    "        df.to_parquet(filepath)\n",
    "        print(f\"Saved {filename} - Shape: {df.shape}\")\n",
    "\n",
    "# Save all the feature sets\n",
    "feature_dfs = [\n",
    "    stock_features,\n",
    "    economic_features,\n",
    "    market_regime_features\n",
    "]\n",
    "\n",
    "feature_filenames = [\n",
    "    \"stock_features.parquet\",\n",
    "    \"economic_features.parquet\",\n",
    "    \"market_regime_features.parquet\"\n",
    "]\n",
    "\n",
    "save_features(feature_dfs, feature_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad1757-3296-4607-9a81-9acdad3b3476",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d3d8fc3-8952-4ea5-b154-9dec8a2f5403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Summary:\n",
      "- Stock features: 94 features generated\n",
      "- Economic features: 30 features generated\n",
      "- Market regime features: 41 features generated\n",
      "\n",
      "Next Steps:\n",
      "1. Evaluate the usefulness of engineered features for portfolio construction\n",
      "2. Refine market regime classification using unsupervised learning\n",
      "3. Implement portfolio construction models using the engineered features\n",
      "4. Backtest different allocation strategies based on these features\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Engineering Summary:\")\n",
    "print(f\"- Stock features: {stock_features.shape[1]} features generated\")\n",
    "print(f\"- Economic features: {economic_features.shape[1]} features generated\")\n",
    "print(f\"- Market regime features: {market_regime_features.shape[1]} features generated\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Evaluate the usefulness of engineered features for portfolio construction\")\n",
    "print(\"2. Refine market regime classification using unsupervised learning\")\n",
    "print(\"3. Implement portfolio construction models using the engineered features\")\n",
    "print(\"4. Backtest different allocation strategies based on these features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3b142-c181-492b-b35d-3515c1c710d3",
   "metadata": {},
   "source": [
    "## 11. Verify Saved Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ae77981-1295-4149-8e49-d31c623f8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in processed data directory:\n",
      "economic_features.parquet - Shape: (4005, 30) - Columns: 30 - Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "market_regime_features.parquet - Shape: (3812, 41) - Columns: 41 - Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "stock_features.parquet - Shape: (3812, 94) - Columns: 94 - Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "# Verify the saved files\n",
    "processed_files = os.listdir(PROCESSED_DATA_PATH)\n",
    "print(\"Files in processed data directory:\")\n",
    "for file in processed_files:\n",
    "    filepath = PROCESSED_DATA_PATH / file\n",
    "    # Load the file to check it can be read back\n",
    "    df = pd.read_parquet(filepath)\n",
    "    print(f\"{file} - Shape: {df.shape} - Columns: {len(df.columns)} - Index type: {type(df.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669532ef-614f-41e6-9c07-593a2fe60332",
   "metadata": {},
   "source": [
    "## 12. Document Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef6519e-342a-468e-87a3-4d10fdbc3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering key insights from processed data...\n"
     ]
    }
   ],
   "source": [
    "# Analyze processed data to gather key insights\n",
    "print(\"Gathering key insights from processed data...\")\n",
    "\n",
    "# Load the processed data files\n",
    "stock_features = pd.read_parquet(PROCESSED_DATA_PATH / \"stock_features.parquet\")\n",
    "economic_features = pd.read_parquet(PROCESSED_DATA_PATH / \"economic_features.parquet\")\n",
    "market_regime_features = pd.read_parquet(PROCESSED_DATA_PATH / \"market_regime_features.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c52e2-bfd5-4260-b49c-c15a14c8884d",
   "metadata": {},
   "source": [
    "### 12.1 Time Period and Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb5911b6-baae-4275-baf2-f3230f91c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. TIME PERIOD AND FREQUENCY ANALYSIS\n",
      "Stock features:\n",
      "  - Date range: 2010-01-04 to 2025-02-27 (5533 days)\n",
      "  - Number of observations: 3812\n",
      "  - Average days between observations: 1.45\n",
      "  - Approximate frequency: daily\n",
      "Economic features:\n",
      "  - Date range: 2010-01-01 to 2025-02-27 (5536 days)\n",
      "  - Number of observations: 4005\n",
      "  - Average days between observations: 1.38\n",
      "  - Approximate frequency: daily\n",
      "Market regime features:\n",
      "  - Date range: 2010-01-04 to 2025-02-27 (5533 days)\n",
      "  - Number of observations: 3812\n",
      "  - Average days between observations: 1.45\n",
      "  - Approximate frequency: daily\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. TIME PERIOD AND FREQUENCY ANALYSIS\")\n",
    "# Ensure index is datetime\n",
    "for df_name, df in zip(['Stock features', 'Economic features', 'Market regime features'], \n",
    "                       [stock_features, economic_features, market_regime_features]):\n",
    "    if not pd.api.types.is_datetime64_dtype(df.index):\n",
    "        try:\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        except:\n",
    "            print(f\"Could not convert index to datetime for {df_name}\")\n",
    "            continue\n",
    "    \n",
    "    start_date = df.index.min()\n",
    "    end_date = df.index.max()\n",
    "    total_days = (end_date - start_date).days\n",
    "    avg_days_between = total_days / (len(df) - 1) if len(df) > 1 else 0\n",
    "    \n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"  - Date range: {start_date.date()} to {end_date.date()} ({total_days} days)\")\n",
    "    print(f\"  - Number of observations: {len(df)}\")\n",
    "    print(f\"  - Average days between observations: {avg_days_between:.2f}\")\n",
    "    \n",
    "    if avg_days_between < 2:\n",
    "        freq = \"daily\"\n",
    "    elif avg_days_between < 8:\n",
    "        freq = \"weekly\"\n",
    "    elif avg_days_between < 32:\n",
    "        freq = \"monthly\"\n",
    "    elif avg_days_between < 95:\n",
    "        freq = \"quarterly\"\n",
    "    else:\n",
    "        freq = \"annual or irregular\"\n",
    "    \n",
    "    print(f\"  - Approximate frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866bac3-bbc7-4211-a7a8-dc61a84fb991",
   "metadata": {},
   "source": [
    "### 12.2 Economic Indicator Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d32d63c-6a11-427d-b513-7520a3a3ddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. ECONOMIC INDICATORS ANALYSIS\n",
      "Number of economic indicators: 30\n",
      "\n",
      "Sample of economic indicators:\n",
      "['GDP', 'UNRATE', 'CPIAUCSL', 'FEDFUNDS', 'T10Y2Y', 'GDP_pct_change', 'GDP_zscore', 'GDP_ma_3m', 'GDP_ma_12m', 'GDP_trend']\n",
      "\n",
      "Summary statistics for economic indicators:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GDP</th>\n",
       "      <td>60.0</td>\n",
       "      <td>20549.782617</td>\n",
       "      <td>4310.087947</td>\n",
       "      <td>14764.610000</td>\n",
       "      <td>17132.473750</td>\n",
       "      <td>19565.619000</td>\n",
       "      <td>22834.810000</td>\n",
       "      <td>29719.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <td>181.0</td>\n",
       "      <td>254.491083</td>\n",
       "      <td>28.788096</td>\n",
       "      <td>217.199000</td>\n",
       "      <td>233.669000</td>\n",
       "      <td>244.243000</td>\n",
       "      <td>266.625000</td>\n",
       "      <td>319.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNRATE</th>\n",
       "      <td>181.0</td>\n",
       "      <td>5.788398</td>\n",
       "      <td>2.234609</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>14.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <td>181.0</td>\n",
       "      <td>1.246409</td>\n",
       "      <td>1.728006</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10Y2Y_zscore</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.085354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.085354</td>\n",
       "      <td>1.085354</td>\n",
       "      <td>1.085354</td>\n",
       "      <td>1.085354</td>\n",
       "      <td>1.085354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10Y2Y_ma_12m</th>\n",
       "      <td>1870.0</td>\n",
       "      <td>1.022017</td>\n",
       "      <td>0.979190</td>\n",
       "      <td>-0.939167</td>\n",
       "      <td>0.240208</td>\n",
       "      <td>1.013333</td>\n",
       "      <td>1.721667</td>\n",
       "      <td>2.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10Y2Y_ma_3m</th>\n",
       "      <td>3386.0</td>\n",
       "      <td>1.016017</td>\n",
       "      <td>0.971170</td>\n",
       "      <td>-1.026667</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>1.023333</td>\n",
       "      <td>1.719167</td>\n",
       "      <td>2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10Y2Y</th>\n",
       "      <td>3791.0</td>\n",
       "      <td>1.012933</td>\n",
       "      <td>0.970092</td>\n",
       "      <td>-1.080000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEDFUNDS_pct_change</th>\n",
       "      <td>4004.0</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDP_pct_change</th>\n",
       "      <td>4004.0</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>-0.082485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count          mean          std           min  \\\n",
       "GDP                    60.0  20549.782617  4310.087947  14764.610000   \n",
       "CPIAUCSL              181.0    254.491083    28.788096    217.199000   \n",
       "UNRATE                181.0      5.788398     2.234609      3.400000   \n",
       "FEDFUNDS              181.0      1.246409     1.728006      0.050000   \n",
       "T10Y2Y_zscore           1.0      1.085354          NaN      1.085354   \n",
       "T10Y2Y_ma_12m        1870.0      1.022017     0.979190     -0.939167   \n",
       "T10Y2Y_ma_3m         3386.0      1.016017     0.971170     -1.026667   \n",
       "T10Y2Y               3791.0      1.012933     0.970092     -1.080000   \n",
       "FEDFUNDS_pct_change  4004.0      0.002142     0.049717     -0.923077   \n",
       "GDP_pct_change       4004.0      0.000178     0.002551     -0.082485   \n",
       "\n",
       "                              25%           50%           75%           max  \n",
       "GDP                  17132.473750  19565.619000  22834.810000  29719.647000  \n",
       "CPIAUCSL               233.669000    244.243000    266.625000    319.086000  \n",
       "UNRATE                   3.900000      5.000000      7.500000     14.800000  \n",
       "FEDFUNDS                 0.090000      0.190000      1.830000      5.330000  \n",
       "T10Y2Y_zscore            1.085354      1.085354      1.085354      1.085354  \n",
       "T10Y2Y_ma_12m            0.240208      1.013333      1.721667      2.858333  \n",
       "T10Y2Y_ma_3m             0.236667      1.023333      1.719167      2.900000  \n",
       "T10Y2Y                   0.240000      1.010000      1.710000      2.910000  \n",
       "FEDFUNDS_pct_change      0.000000      0.000000      0.000000      1.500000  \n",
       "GDP_pct_change           0.000000      0.000000      0.000000      0.087739  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n2. ECONOMIC INDICATORS ANALYSIS\")\n",
    "if len(economic_features.columns) > 0:\n",
    "    print(f\"Number of economic indicators: {len(economic_features.columns)}\")\n",
    "    print(\"\\nSample of economic indicators:\")\n",
    "    print(economic_features.columns.tolist()[:10])\n",
    "    \n",
    "    # Calculate basic statistics for economic indicators\n",
    "    print(\"\\nSummary statistics for economic indicators:\")\n",
    "    display(economic_features.describe().T.sort_values('mean', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"No economic indicators found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225abae2-ac6e-4e11-bade-8b3623748fd7",
   "metadata": {},
   "source": [
    "### 12.3 Asset Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a93c5f33-77df-4204-a9e4-01d39320e1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ASSET CLASS PERFORMANCE ANALYSIS\n",
      "Annualized performance metrics by asset (%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ann_Return</th>\n",
       "      <th>Ann_Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Max_Drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>14.132227</td>\n",
       "      <td>17.014553</td>\n",
       "      <td>0.830596</td>\n",
       "      <td>-33.717264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNQ</th>\n",
       "      <td>10.918854</td>\n",
       "      <td>20.674756</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>-42.398173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEA</th>\n",
       "      <td>7.186258</td>\n",
       "      <td>18.488581</td>\n",
       "      <td>0.388686</td>\n",
       "      <td>-35.735079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLD</th>\n",
       "      <td>7.026526</td>\n",
       "      <td>15.482892</td>\n",
       "      <td>0.453825</td>\n",
       "      <td>-45.555013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VWO</th>\n",
       "      <td>5.319318</td>\n",
       "      <td>20.683012</td>\n",
       "      <td>0.257183</td>\n",
       "      <td>-36.392357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGG</th>\n",
       "      <td>2.517139</td>\n",
       "      <td>4.749973</td>\n",
       "      <td>0.529927</td>\n",
       "      <td>-18.432950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_lower_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_middle_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_std_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_upper_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cum_return</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cum_return_ytd</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_range</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drawdown</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_12d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_26d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_1d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma_200d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma_50d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_hist</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_signal</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_drawdown_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_120d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_252d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_percentile_120d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_percentile_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_percentile_252d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_percentile_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_120d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_1d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_252d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_5d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_120d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_252d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolling_mean_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolling_range_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolling_sharpe_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolling_std_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsi_14d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running_max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_120d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_60d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume_ratio_20d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ann_Return  Ann_Volatility  Sharpe_Ratio  Max_Drawdown\n",
       "SPY                     14.132227       17.014553      0.830596    -33.717264\n",
       "VNQ                     10.918854       20.674756      0.528125    -42.398173\n",
       "VEA                      7.186258       18.488581      0.388686    -35.735079\n",
       "GLD                      7.026526       15.482892      0.453825    -45.555013\n",
       "VWO                      5.319318       20.683012      0.257183    -36.392357\n",
       "AGG                      2.517139        4.749973      0.529927    -18.432950\n",
       "bb_lower_20d                  NaN             NaN           NaN           NaN\n",
       "bb_middle_20d                 NaN             NaN           NaN           NaN\n",
       "bb_std_20d                    NaN             NaN           NaN           NaN\n",
       "bb_upper_20d                  NaN             NaN           NaN           NaN\n",
       "cum_return                    NaN             NaN           NaN           NaN\n",
       "cum_return_ytd                NaN             NaN           NaN           NaN\n",
       "daily_range                   NaN             NaN           NaN           NaN\n",
       "drawdown                      NaN             NaN           NaN           NaN\n",
       "ema_12d                       NaN             NaN           NaN           NaN\n",
       "ema_26d                       NaN             NaN           NaN           NaN\n",
       "log_return_1d                 NaN             NaN           NaN           NaN\n",
       "ma_200d                       NaN             NaN           NaN           NaN\n",
       "ma_20d                        NaN             NaN           NaN           NaN\n",
       "ma_50d                        NaN             NaN           NaN           NaN\n",
       "macd                          NaN             NaN           NaN           NaN\n",
       "macd_hist                     NaN             NaN           NaN           NaN\n",
       "macd_signal                   NaN             NaN           NaN           NaN\n",
       "max_drawdown_60d              NaN             NaN           NaN           NaN\n",
       "momentum_120d                 NaN             NaN           NaN           NaN\n",
       "momentum_20d                  NaN             NaN           NaN           NaN\n",
       "momentum_252d                 NaN             NaN           NaN           NaN\n",
       "momentum_60d                  NaN             NaN           NaN           NaN\n",
       "price_percentile_120d         NaN             NaN           NaN           NaN\n",
       "price_percentile_20d          NaN             NaN           NaN           NaN\n",
       "price_percentile_252d         NaN             NaN           NaN           NaN\n",
       "price_percentile_60d          NaN             NaN           NaN           NaN\n",
       "return_120d                   NaN             NaN           NaN           NaN\n",
       "return_1d                     NaN             NaN           NaN           NaN\n",
       "return_20d                    NaN             NaN           NaN           NaN\n",
       "return_252d                   NaN             NaN           NaN           NaN\n",
       "return_5d                     NaN             NaN           NaN           NaN\n",
       "return_60d                    NaN             NaN           NaN           NaN\n",
       "roc_120d                      NaN             NaN           NaN           NaN\n",
       "roc_20d                       NaN             NaN           NaN           NaN\n",
       "roc_252d                      NaN             NaN           NaN           NaN\n",
       "roc_60d                       NaN             NaN           NaN           NaN\n",
       "rolling_mean_20d              NaN             NaN           NaN           NaN\n",
       "rolling_range_20d             NaN             NaN           NaN           NaN\n",
       "rolling_sharpe_20d            NaN             NaN           NaN           NaN\n",
       "rolling_std_20d               NaN             NaN           NaN           NaN\n",
       "rsi_14d                       NaN             NaN           NaN           NaN\n",
       "running_max                   NaN             NaN           NaN           NaN\n",
       "volatility_120d               NaN             NaN           NaN           NaN\n",
       "volatility_20d                NaN             NaN           NaN           NaN\n",
       "volatility_60d                NaN             NaN           NaN           NaN\n",
       "volume_ratio_20d              NaN             NaN           NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asset correlation matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGG</th>\n",
       "      <th>GLD</th>\n",
       "      <th>SPY</th>\n",
       "      <th>VEA</th>\n",
       "      <th>VNQ</th>\n",
       "      <th>VWO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301862</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>0.173118</td>\n",
       "      <td>0.019880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLD</th>\n",
       "      <td>0.301862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.142704</td>\n",
       "      <td>0.116384</td>\n",
       "      <td>0.170011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870928</td>\n",
       "      <td>0.755611</td>\n",
       "      <td>0.779166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEA</th>\n",
       "      <td>0.027621</td>\n",
       "      <td>0.142704</td>\n",
       "      <td>0.870928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.855854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNQ</th>\n",
       "      <td>0.173118</td>\n",
       "      <td>0.116384</td>\n",
       "      <td>0.755611</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VWO</th>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.170011</td>\n",
       "      <td>0.779166</td>\n",
       "      <td>0.855854</td>\n",
       "      <td>0.607542</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AGG       GLD       SPY       VEA       VNQ       VWO\n",
       "AGG  1.000000  0.301862  0.003325  0.027621  0.173118  0.019880\n",
       "GLD  0.301862  1.000000  0.056152  0.142704  0.116384  0.170011\n",
       "SPY  0.003325  0.056152  1.000000  0.870928  0.755611  0.779166\n",
       "VEA  0.027621  0.142704  0.870928  1.000000  0.696940  0.855854\n",
       "VNQ  0.173118  0.116384  0.755611  0.696940  1.000000  0.607542\n",
       "VWO  0.019880  0.170011  0.779166  0.855854  0.607542  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n3. ASSET CLASS PERFORMANCE ANALYSIS\")\n",
    "# Identify ETF tickers in the stock data\n",
    "if isinstance(stock_features.columns, pd.MultiIndex):\n",
    "    # For MultiIndex columns\n",
    "    tickers = sorted(set([col[0] for col in stock_features.columns if isinstance(col, tuple)]))\n",
    "    \n",
    "    # Extract close prices for each ticker\n",
    "    close_prices = {}\n",
    "    returns = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        # Find close price column for this ticker\n",
    "        close_cols = [col for col in stock_features.columns if isinstance(col, tuple) and col[0] == ticker and 'close' in col[1].lower()]\n",
    "        if close_cols:\n",
    "            close_col = close_cols[0]\n",
    "            close_prices[ticker] = stock_features[close_col]\n",
    "            # Calculate returns\n",
    "            returns[ticker] = stock_features[close_col].pct_change()\n",
    "    \n",
    "    # Create DataFrame of returns\n",
    "    returns_df = pd.DataFrame(returns)\n",
    "    \n",
    "    # Calculate annualized metrics\n",
    "    annualized_metrics = pd.DataFrame(index=tickers)\n",
    "    annualized_metrics['Ann_Return'] = returns_df.mean() * 252 * 100  # Assuming daily data\n",
    "    annualized_metrics['Ann_Volatility'] = returns_df.std() * np.sqrt(252) * 100\n",
    "    annualized_metrics['Sharpe_Ratio'] = annualized_metrics['Ann_Return'] / annualized_metrics['Ann_Volatility']\n",
    "    \n",
    "    # Calculate max drawdown\n",
    "    cum_returns = (1 + returns_df).cumprod()\n",
    "    running_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns / running_max - 1)\n",
    "    annualized_metrics['Max_Drawdown'] = drawdown.min() * 100\n",
    "    \n",
    "    # Display results sorted by return\n",
    "    print(\"Annualized performance metrics by asset (%):\")\n",
    "    display(annualized_metrics.sort_values('Ann_Return', ascending=False))\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    print(\"\\nAsset correlation matrix:\")\n",
    "    display(returns_df.corr())\n",
    "else:\n",
    "    print(\"Cannot extract ticker performance from non-MultiIndex columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390abd7d-910c-4a76-957d-c7988ba4ffe8",
   "metadata": {},
   "source": [
    "### 12.4 Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21410510-3dde-471d-8cac-2c2a8416146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. FEATURE CORRELATION ANALYSIS\n",
      "Top features correlated with returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ticker                Price\n",
       "return_1d                      1.000000\n",
       "log_return_1d                  0.999923\n",
       "return_5d                      0.446694\n",
       "price_percentile_20d           0.391352\n",
       "rsi_14d                        0.252408\n",
       "price_percentile_60d           0.238417\n",
       "return_20d                     0.209229\n",
       "roc_20d                        0.209229\n",
       "rolling_mean_20d               0.209090\n",
       "rolling_sharpe_20d             0.206996\n",
       "Name: (return_1d, ), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom features correlated with returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ticker            Price\n",
       "ma_20d                     0.001424\n",
       "bb_lower_20d              -0.000765\n",
       "macd_signal               -0.004352\n",
       "running_max               -0.007333\n",
       "volatility_120d           -0.008760\n",
       "volatility_20d            -0.014341\n",
       "rolling_std_20d           -0.014341\n",
       "volatility_60d            -0.016412\n",
       "volume_ratio_20d          -0.084820\n",
       "daily_range               -0.102490\n",
       "Name: (return_1d, ), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n4. FEATURE CORRELATION ANALYSIS\")\n",
    "# Try to find return columns for correlation analysis\n",
    "return_cols = []\n",
    "\n",
    "if isinstance(stock_features.columns, pd.MultiIndex):\n",
    "    # For MultiIndex columns, look for return_1d in the first level\n",
    "    return_cols = [col for col in stock_features.columns if col[0] == 'return_1d' or \n",
    "                  (isinstance(col, tuple) and len(col) >= 2 and col[1] == '' and col[0] == 'return_1d')]\n",
    "else:\n",
    "    # For regular columns\n",
    "    return_cols = [col for col in stock_features.columns if 'return_1d' in str(col)]\n",
    "\n",
    "# If we found return columns, analyze correlations\n",
    "if return_cols:\n",
    "    return_col = return_cols[0]\n",
    "    \n",
    "    # Create a DataFrame for correlation analysis\n",
    "    if isinstance(stock_features.columns, pd.MultiIndex):\n",
    "        # For MultiIndex, select columns with empty second level (features)\n",
    "        feature_cols = [col for col in stock_features.columns if isinstance(col, tuple) and col[1] == '']\n",
    "        correlation_df = stock_features[feature_cols]\n",
    "    else:\n",
    "        correlation_df = stock_features\n",
    "    \n",
    "    # Calculate correlations with returns\n",
    "    if return_col in correlation_df.columns:\n",
    "        correlations = correlation_df.corr()[return_col].sort_values(ascending=False)\n",
    "        \n",
    "        print(\"Top features correlated with returns:\")\n",
    "        display(correlations.head(10))\n",
    "        \n",
    "        print(\"\\nBottom features correlated with returns:\")\n",
    "        display(correlations.tail(10))\n",
    "    else:\n",
    "        print(f\"Return column {return_col} not found in filtered DataFrame.\")\n",
    "else:\n",
    "    print(\"No return columns found for correlation analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90fff59-fe82-4878-9da4-2c867ad3e2bc",
   "metadata": {},
   "source": [
    "### 12.5 Market Regime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29d6ac0-0022-4226-ba81-33e4abf83b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. MARKET REGIME ANALYSIS\n",
      "Market regime distribution:\n",
      "  - bull_stable: 1512 days (39.66%)\n",
      "  - bear_stable: 1332 days (34.94%)\n",
      "  - bull_volatile: 494 days (12.96%)\n",
      "  - bear_volatile: 454 days (11.91%)\n",
      "  - undefined: 20 days (0.52%)\n",
      "\n",
      "Return characteristics by market regime:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>annualized_return</th>\n",
       "      <th>annualized_vol</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_regime_basic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bull_volatile</th>\n",
       "      <td>1.008120</td>\n",
       "      <td>0.849978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.903838</td>\n",
       "      <td>494</td>\n",
       "      <td>254.046208</td>\n",
       "      <td>13.492988</td>\n",
       "      <td>18.828017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bull_stable</th>\n",
       "      <td>0.588090</td>\n",
       "      <td>0.505759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.480887</td>\n",
       "      <td>1512</td>\n",
       "      <td>148.198609</td>\n",
       "      <td>8.028679</td>\n",
       "      <td>18.458654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undefined</th>\n",
       "      <td>-0.063154</td>\n",
       "      <td>1.196361</td>\n",
       "      <td>-2.313481</td>\n",
       "      <td>2.255568</td>\n",
       "      <td>19</td>\n",
       "      <td>-15.914787</td>\n",
       "      <td>18.991639</td>\n",
       "      <td>-0.837989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bear_volatile</th>\n",
       "      <td>-1.076287</td>\n",
       "      <td>1.028147</td>\n",
       "      <td>-8.780826</td>\n",
       "      <td>-0.004643</td>\n",
       "      <td>454</td>\n",
       "      <td>-271.224420</td>\n",
       "      <td>16.321322</td>\n",
       "      <td>-16.617798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bear_stable</th>\n",
       "      <td>-0.593924</td>\n",
       "      <td>0.519476</td>\n",
       "      <td>-3.471113</td>\n",
       "      <td>-0.005999</td>\n",
       "      <td>1332</td>\n",
       "      <td>-149.668743</td>\n",
       "      <td>8.246428</td>\n",
       "      <td>-18.149525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       std       min       max  count  \\\n",
       "market_regime_basic                                                  \n",
       "bull_volatile        1.008120  0.849978  0.000000  4.903838    494   \n",
       "bull_stable          0.588090  0.505759  0.000000  3.480887   1512   \n",
       "undefined           -0.063154  1.196361 -2.313481  2.255568     19   \n",
       "bear_volatile       -1.076287  1.028147 -8.780826 -0.004643    454   \n",
       "bear_stable         -0.593924  0.519476 -3.471113 -0.005999   1332   \n",
       "\n",
       "                     annualized_return  annualized_vol     sharpe  \n",
       "market_regime_basic                                                \n",
       "bull_volatile               254.046208       13.492988  18.828017  \n",
       "bull_stable                 148.198609        8.028679  18.458654  \n",
       "undefined                   -15.914787       18.991639  -0.837989  \n",
       "bear_volatile              -271.224420       16.321322 -16.617798  \n",
       "bear_stable                -149.668743        8.246428 -18.149525  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n5. MARKET REGIME ANALYSIS\")\n",
    "if 'market_regime_basic' in market_regime_features.columns:\n",
    "    regime_counts = market_regime_features['market_regime_basic'].value_counts()\n",
    "    regime_pct = market_regime_features['market_regime_basic'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Market regime distribution:\")\n",
    "    for regime, count in regime_counts.items():\n",
    "        print(f\"  - {regime}: {count} days ({regime_pct[regime]:.2f}%)\")\n",
    "    \n",
    "    # Analyze returns by regime\n",
    "    if 'market_return' in market_regime_features.columns:\n",
    "        print(\"\\nReturn characteristics by market regime:\")\n",
    "        regime_returns = market_regime_features.groupby('market_regime_basic')['market_return'].agg(\n",
    "            ['mean', 'std', 'min', 'max', 'count']\n",
    "        )\n",
    "        regime_returns['mean'] *= 100  # Convert to percentage\n",
    "        regime_returns['std'] *= 100\n",
    "        regime_returns['min'] *= 100\n",
    "        regime_returns['max'] *= 100\n",
    "        regime_returns['annualized_return'] = regime_returns['mean'] * 252\n",
    "        regime_returns['annualized_vol'] = regime_returns['std'] * np.sqrt(252)\n",
    "        regime_returns['sharpe'] = regime_returns['annualized_return'] / regime_returns['annualized_vol']\n",
    "        \n",
    "        display(regime_returns.sort_values('sharpe', ascending=False))\n",
    "else:\n",
    "    print(\"No market regime classification found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368f508-fa8c-4405-bf79-21cf02562417",
   "metadata": {},
   "source": [
    "### Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92222297-cf0f-41a0-b1e0-393d9046efc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. DATA QUALITY ANALYSIS\n",
      "Stock features:\n",
      "  - Total observations: 3812, Total features: 94\n",
      "  - Missing values: 2528 (0.71%)\n",
      "Economic features:\n",
      "  - Total observations: 4005, Total features: 30\n",
      "  - Missing values: 88616 (73.75%)\n",
      "  - Columns with >10% missing values: 24\n",
      "    Top 5: ['UNRATE_ma_3m', 'UNRATE_zscore', 'GDP_trend', 'GDP_ma_12m', 'GDP_ma_3m']\n",
      "Market regime features:\n",
      "  - Total observations: 3812, Total features: 41\n",
      "  - Missing values: 84272 (53.92%)\n",
      "  - Columns with >10% missing values: 24\n",
      "    Top 5: ['FEDFUNDS_ma_12m', 'GDP_ma_3m', 'GDP_ma_12m', 'GDP_trend', 'UNRATE_zscore']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6. DATA QUALITY ANALYSIS\")\n",
    "for df_name, df in zip(['Stock features', 'Economic features', 'Market regime features'], \n",
    "                       [stock_features, economic_features, market_regime_features]):\n",
    "    missing_count = df.isna().sum().sum()\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    missing_pct = missing_count / total_cells * 100 if total_cells > 0 else 0\n",
    "    \n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"  - Total observations: {df.shape[0]}, Total features: {df.shape[1]}\")\n",
    "    print(f\"  - Missing values: {missing_count} ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Check for columns with high missing values\n",
    "    if missing_count > 0:\n",
    "        col_missing = df.isna().sum().sort_values(ascending=False)\n",
    "        high_missing = col_missing[col_missing > 0.1 * df.shape[0]]  # >10% missing\n",
    "        if len(high_missing) > 0:\n",
    "            print(f\"  - Columns with >10% missing values: {len(high_missing)}\")\n",
    "            print(\"    Top 5:\", high_missing.index.tolist()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5189b66-f69f-43b0-bd89-7e65f558bb1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Key Insights from Feature Engineering\n",
    "### Time Period and Frequency\n",
    "\n",
    "The dataset covers a long period from January 2010 to February 2025, spanning over 15 years and including approximately 3,800-4,000 daily observations\n",
    "The daily frequency provides granular visibility into market movements across multiple economic cycles\n",
    "The time range captures several significant market events including the post-2008 recovery, bull market of the 2010s, COVID-19 crash, and subsequent recovery\n",
    "\n",
    "## Asset Class Performance Insights\n",
    "\n",
    "- US equities (SPY) delivered the strongest returns with annualized return of 14.13% and a Sharpe ratio of 0.83\n",
    "- Real Estate (VNQ) provided the second-best returns (10.92%) but with higher volatility (20.67%)\n",
    "- Fixed income (AGG) showed the lowest volatility (4.75%) and modest returns (2.52%), consistent with its risk profile\n",
    "- Gold (GLD) offered moderate returns (7.03%) with reasonable volatility (15.48%)\n",
    "- International equities (VEA, VWO) underperformed US equities, with developed markets (VEA: 7.19%) outperforming emerging markets (VWO: 5.32%)\n",
    "- The maximum drawdowns varied significantly across asset classes, from -18.43% for bonds (AGG) to -45.56% for gold (GLD)\n",
    "\n",
    "## Correlation Analysis\n",
    "\n",
    "- US stocks (SPY) show strong correlations with international equities (VEA: 0.87, VWO: 0.78) and real estate (VNQ: 0.76)\n",
    "- Gold (GLD) exhibits low correlation with equities (SPY: 0.06) and moderate correlation with bonds (AGG: 0.30), confirming its diversification benefits\n",
    "- Bonds (AGG) demonstrate very low correlation with equities (SPY: 0.003), highlighting their effectiveness as a diversifier\n",
    "- The correlation structure supports the traditional diversification principles across these major asset classes\n",
    "\n",
    "## Feature Significance\n",
    "\n",
    "- Short-term return features (return_1d, log_return_1d, return_5d) show the strongest correlation with future returns\n",
    "- Price percentile indicators (price_percentile_20d, price_percentile_60d) have meaningful correlations, suggesting momentum effects\n",
    "- RSI (Relative Strength Index) appears to have predictive value with a correlation of 0.25\n",
    "- Technical indicators like moving averages (ma_20d) show minimal correlation with returns, suggesting limited predictive power\n",
    "- Volatility measures (volatility_20d, volatility_60d, volatility_120d) show slight negative correlations with returns\n",
    "\n",
    "## Market Regime Characteristics\n",
    "\n",
    "- The market spent the largest portion of time (39.66%) in bull_stable regimes, followed by bear_stable (34.94%)\n",
    "- Volatile regimes were less common, with bull_volatile at 12.96% and bear_volatile at 11.91% of days\n",
    "- Performance varied dramatically across regimes:\n",
    "\n",
    "    - Bull_volatile regimes delivered the highest annualized returns (254.05%) with high volatility (13.49%)\n",
    "    - Bull_stable periods provided strong returns (148.20%) with lower volatility (8.03%)\n",
    "    - Bear regimes showed substantial negative returns, with bear_volatile (-271.22%) and bear_stable (-149.67%)\n",
    "    - The highest Sharpe ratios occurred during bull regimes, especially bull_volatile (18.83)\n",
    "\n",
    "\n",
    "\n",
    "## Economic Indicators Insights\n",
    "\n",
    "- Key macroeconomic variables include GDP, inflation (CPIAUCSL), unemployment (UNRATE), interest rates (FEDFUNDS), and yield curve spreads (T10Y2Y)\n",
    "- The unemployment rate varied significantly from 3.4% to 14.8%, capturing both strong economic periods and the COVID-19 pandemic impact\n",
    "- The Federal Funds Rate ranged from near-zero (0.05%) to 5.33%, reflecting the full monetary policy cycle\n",
    "- The dataset includes derived features like percentage changes, z-scores, moving averages, and trend indicators to capture different aspects of economic conditions\n",
    "\n",
    "## Data Quality Considerations\n",
    "\n",
    "- Stock features have high quality with minimal missing values (0.71%)\n",
    "- Economic features contain significant missing data (73.75%), particularly in derived features like moving averages and z-scores\n",
    "- Market regime features also show substantial missing values (53.92%), largely due to their dependence on economic indicators\n",
    "- Key economic indicators with the most missing data include unemployment and GDP metrics, which likely reflects their less frequent release schedule compared to market data\n",
    "\n",
    "## Engineering Challenges and Solutions\n",
    "\n",
    "- The MultiIndex column structure required specialized approaches for feature engineering and analysis\n",
    "- The integration of market data (daily) with economic data (often released monthly or quarterly) created alignment challenges\n",
    "- The feature engineering process successfully created a comprehensive set of 94 stock features, 30 economic features, and 41 market regime features\n",
    "- The approach clearly separated different market regimes, enabling regime-based investment strategies\n",
    "\n",
    "These insights provide a solid foundation for developing baseline portfolio allocation models and more advanced strategies. The diverse asset classes, comprehensive feature set, and clearly defined market regimes offer multiple approaches for constructing and evaluating investment portfolios across different economic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62547d0-0af7-4b01-8baa-894dae876950",
   "metadata": {},
   "source": [
    "## 13. Identify Potential Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a780b9f2-54dd-4972-b5b8-634b0aba30c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing value analysis:\n",
      "Stock features: 2528 missing values (0.71%)\n",
      "Top 5 columns with missing values:\n",
      "Ticker                 Price\n",
      "roc_252d                        252\n",
      "return_252d                     252\n",
      "momentum_252d                   252\n",
      "price_percentile_252d           251\n",
      "ma_200d                         199\n",
      "dtype: int64\n",
      "Economic features: 88616 missing values (73.75%)\n",
      "Top 5 columns with missing values:\n",
      "UNRATE_ma_3m     4005\n",
      "UNRATE_zscore    4005\n",
      "GDP_trend        4005\n",
      "GDP_ma_12m       4005\n",
      "GDP_ma_3m        4005\n",
      "dtype: int64\n",
      "Market regime features: 84272 missing values (53.92%)\n",
      "Top 5 columns with missing values:\n",
      "FEDFUNDS_ma_12m    3812\n",
      "GDP_ma_3m          3812\n",
      "GDP_ma_12m         3812\n",
      "GDP_trend          3812\n",
      "UNRATE_zscore      3812\n",
      "dtype: int64\n",
      "\n",
      "Outlier analysis:\n",
      "Stock features: 2639 potential outliers (0.74%)\n",
      "Economic features: 208 potential outliers (0.17%)\n",
      "Market regime features: 429 potential outliers (0.28%)\n",
      "\n",
      "Time period analysis:\n",
      "Stock features observations by year:\n",
      "Date\n",
      "2010    252\n",
      "2011    252\n",
      "2012    250\n",
      "2013    252\n",
      "2014    252\n",
      "2015    252\n",
      "2016    252\n",
      "2017    251\n",
      "2018    251\n",
      "2019    252\n",
      "2020    253\n",
      "2021    252\n",
      "2022    251\n",
      "2023    250\n",
      "2024    252\n",
      "2025     38\n",
      "dtype: int64\n",
      "Economic features observations by year:\n",
      "2010    263\n",
      "2011    263\n",
      "2012    266\n",
      "2013    264\n",
      "2014    265\n",
      "2015    265\n",
      "2016    263\n",
      "2017    264\n",
      "2018    265\n",
      "2019    264\n",
      "2020    266\n",
      "2021    263\n",
      "2022    263\n",
      "2023    264\n",
      "2024    265\n",
      "2025     42\n",
      "dtype: int64\n",
      "Market regime features observations by year:\n",
      "Date\n",
      "2010    252\n",
      "2011    252\n",
      "2012    250\n",
      "2013    252\n",
      "2014    252\n",
      "2015    252\n",
      "2016    252\n",
      "2017    251\n",
      "2018    251\n",
      "2019    252\n",
      "2020    253\n",
      "2021    252\n",
      "2022    251\n",
      "2023    250\n",
      "2024    252\n",
      "2025     38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataset\n",
    "print(\"\\nMissing value analysis:\")\n",
    "for df_name, df_file in zip(\n",
    "    ['Stock features', 'Economic features', 'Market regime features'],\n",
    "    ['stock_features.parquet', 'economic_features.parquet', 'market_regime_features.parquet']\n",
    "):\n",
    "    df = pd.read_parquet(PROCESSED_DATA_PATH / df_file)\n",
    "    missing_count = df.isna().sum().sum()\n",
    "    missing_pct = missing_count / (df.shape[0] * df.shape[1]) * 100\n",
    "    print(f\"{df_name}: {missing_count} missing values ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # Show columns with the most missing values\n",
    "    col_missing = df.isna().sum().sort_values(ascending=False)\n",
    "    if col_missing.max() > 0:\n",
    "        print(\"Top 5 columns with missing values:\")\n",
    "        print(col_missing[col_missing > 0].head())\n",
    "\n",
    "# Check for data points at the boundaries (potential outliers)\n",
    "print(\"\\nOutlier analysis:\")\n",
    "for df_name, df_file in zip(\n",
    "    ['Stock features', 'Economic features', 'Market regime features'],\n",
    "    ['stock_features.parquet', 'economic_features.parquet', 'market_regime_features.parquet']\n",
    "):\n",
    "    df = pd.read_parquet(PROCESSED_DATA_PATH / df_file)\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Calculate z-scores for each column\n",
    "    z_scores = (numeric_df - numeric_df.mean()) / numeric_df.std()\n",
    "    \n",
    "    # Count potential outliers (|z| > 3)\n",
    "    outlier_count = (abs(z_scores) > 3).sum().sum()\n",
    "    outlier_pct = outlier_count / (numeric_df.shape[0] * numeric_df.shape[1]) * 100\n",
    "    print(f\"{df_name}: {outlier_count} potential outliers ({outlier_pct:.2f}%)\")\n",
    "\n",
    "# Check for time periods with sparse data\n",
    "print(\"\\nTime period analysis:\")\n",
    "for df_name, df_file in zip(\n",
    "    ['Stock features', 'Economic features', 'Market regime features'],\n",
    "    ['stock_features.parquet', 'economic_features.parquet', 'market_regime_features.parquet']\n",
    "):\n",
    "    df = pd.read_parquet(PROCESSED_DATA_PATH / df_file)\n",
    "    \n",
    "    # Ensure index is datetime\n",
    "    if not pd.api.types.is_datetime64_dtype(df.index):\n",
    "        try:\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        except:\n",
    "            print(f\"Could not convert index to datetime for {df_name}\")\n",
    "            continue\n",
    "    \n",
    "    # Group by year and count observations\n",
    "    yearly_counts = df.groupby(df.index.year).size()\n",
    "    print(f\"{df_name} observations by year:\")\n",
    "    print(yearly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3cd966-c301-4b16-910f-b313c3fb08cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
